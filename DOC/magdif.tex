\documentclass[a4paper, twoside, 10pt, english]{article}
\setlength\overfullrule{5pt}

% eTeX stuff
\usepackage{etoolbox}

% fonts and maths
\usepackage{fontspec}
%\setmainfont{TeX Gyre Pagella}
%\setsansfont{TeX Gyre Heros}
%\setmonofont[Scale=MatchLowercase]{Source Code Pro}
\usepackage{luatexbase} % needed to correct bug in microtype w.r.t. LuaTeX
\usepackage{microtype}
\usepackage[normalem]{ulem}
\usepackage{amsmath}  % [fleqn]
\usepackage{cancel}
\allowdisplaybreaks[1]
\numberwithin{equation}{section}
\usepackage[math-style=ISO, bold-style=ISO]{unicode-math}
%\setmathfont{TeX Gyre Pagella Math}
%\setmathfont{Latin Modern Math}[range=\dagger]
\DeclareSymbolFont{AMSb}{U}{msb}{m}{n}
\protected\def\mathbb#1{{\mathchar\numexpr256*\symAMSb+`#1\relax}}
\AfterPreamble{%
  \let\temp\varrho
  \let\varrho\rho
  \let\rho\temp
  \let\temp\vartheta
  \let\vartheta\theta
  \let\theta\temp
  \let\temp\varphi
  \let\varphi\phi
  \let\phi\temp
  \let\vecarr\vec
  \let\vec\symbf
}

% language
\usepackage{polyglossia}
\setmainlanguage{english}
\usepackage{csquotes}
\MakeOuterQuote{"}

% tables
\usepackage{array}
\usepackage{ragged2e}
%\usepackage{tabularx}
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}

% graphics
\usepackage{xcolor}
\newcommand\comment[1]{\begingroup\color{red}[#1]\endgroup}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{tikz}
\usetikzlibrary{math, arrows.meta, calc, intersections}

% import and display data
\usepackage{siunitx}
\sisetup{
  group-digits = false,
  add-decimal-zero = false,
  retain-unity-mantissa = false,
  separate-uncertainty,
  round-mode = off,
  %round-precision = 2,
  table-number-alignment = left,
  detect-mode = true
}

% (pseudo)code
\usepackage{algorithm}
\usepackage{algpseudocode}

% page layout
\raggedbottom
\tolerance=2000
\usepackage{enumitem}
\setlist{align=left}
\usepackage{parskip}
%\usepackage{setspace}
%\setstretch{1.125}
\usepackage{lastpage}
\usepackage[margin=2cm, head=15pt, includehead, includefoot]{geometry}
\usepackage[bottom, stable, perpage]{footmisc}
\usepackage{fancyhdr}
\fancyhf{}
\fancyfoot[C]{\thepage/\pageref{LastPage}}
\fancyhead[RO]{\textsl{\rightmark}}
\fancyhead[LE]{\textsl{\leftmark}}
\pagestyle{fancy}
\renewcommand{\sectionmark}[1]{\markboth{\thesection~#1}{}}
\renewcommand{\subsectionmark}[1]{\markright{\thesubsection~#1}}

% front and back matter
\usepackage{eso-pic}
\usepackage[
  backend = biber,
  bibstyle = numeric,
  citestyle = authoryear,
  sorting = none,
  maxcitenames = 1,
  maxbibnames = 5
]{biblatex}
\renewcommand*\finalnamedelim{,\ }
\DefineBibliographyStrings{english}{%
  andothers        = {et\,al\adddot},
  andmore          = {et\,al\adddot}
}
\addbibresource{magdif.bib}
\usepackage[
% pdfa         = true,
  unicode      = true,
  bookmarks    = true,
  colorlinks   = true,
  linkcolor    = black,
  urlcolor     = black,
  citecolor    = black,
  pdfstartview = FitH
]{hyperref}
\hypersetup{
  pdftitle    = {Magnetic differential equations for stationary linear ideal MHD and their numerical solution},
  pdfauthor   = {Christoper Albert, Patrick Lainer},
  pdfsubject  = {write-up},
  pdfkeywords = {magnetohydrodynamics},
  pdflang     = {en}
}

% references
\usepackage{cleveref}

% debugging
%\usepackage[inline]{showlabels}
%\usepackage[notref]{showkeys}

\title{Magnetic differential equations for stationary linear ideal MHD and their numerical solution}
\author{Christopher Albert, Patrick Lainer}

% math shortcuts etc.
\DeclareMathOperator\Real{Re}
\DeclareMathOperator\Imag{Im}
\DeclareMathOperator\sgn{sgn}
\newcommand*\grad{\ensuremath{\nabla}}
\newcommand*\divg{\ensuremath{\nabla \cdot}}
\newcommand*\curl{\ensuremath{\nabla \times}}
\DeclareMathOperator\Grad{\mathbf{grad}}
\DeclareMathOperator\Divg{div}
\DeclareMathOperator\Curl{\mathbf{rot}}

\newcommand*\diff{\ensuremath{\symrm{d}}}  % differential
\newcommand*\e{\ensuremath{\symrm{e}}}  % Euler's constant
\newcommand*\im{\ensuremath{\symrm{i}}}  % imaginary unit
\newcommand*\pd[2][]{\ensuremath{\frac{\partial #1}{\partial #2}}}  % partial derivative
\newcommand*\td[2][]{\ensuremath{\frac{\diff #1}{\diff #2}}}  % total derivative
\newcommand*\norm[1]{\ensuremath{\left \lVert #1 \right \rVert}}  % norm
\newcommand*\pol{\ensuremath{\textrm{pol}}}  % poloidal
\newcommand*\tor{\ensuremath{\textrm{tor}}}  % toroidal
\newcommand*\polGrad{\ensuremath{\Grad_{\pol}}}  % transverse gradient
\newcommand*\polDivg{\ensuremath{\Divg_{\pol}}}  % transverse divergence
\newcommand*\polCurlvec{\ensuremath{\Curl_{\pol}}}  % transverse vector curl
\newcommand*\polCurl{\ensuremath{\operatorname{rot}_{\pol}}}  % transverse scalar curl

\newcommand*\Bvac{\ensuremath{\delta \vec{B}_{\text{v}}}}  % vacuum field
\newcommand*\Bplas{\ensuremath{\delta \vec{B}_{\text{p}}}}  % plasma response
\newcommand*\Bpert{\ensuremath{\delta \vec{B}}}  % full perturbation
\newcommand*\fs{\ensuremath{\textrm{f}}}  % flux surface edge label
\newcommand*\inw{\ensuremath{\textrm{i}}}  % inward current edge label
\newcommand*\out{\ensuremath{\textrm{o}}}  % outward current edge label
\newcommand*\vfs{\ensuremath{\textrm{F}}}  % label for vertex opposite flux surface edge
\newcommand*\vinw{\ensuremath{\textrm{I}}}  % label for vertex opposite inward current edge
\newcommand*\vout{\ensuremath{\textrm{O}}}  % label for vertex opposite outward current edge

\begin{document}

\maketitle
\tableofcontents

\newpage
\section{Ideal magneotohydrodynamics}

[derivation of the stationary equilibrium, flux surfaces and \textsc{Grad}--\textsc{Shafranov} equation, flux surface quantities, \ldots]

\textcite{dHaeseleer91} defines the flux-surface average of an arbitrary quantity $\Phi$ in a toroidal system as
\begin{gather}
  \langle \Phi \rangle = \frac{\int_{0}^{2 \pi} \int_{0}^{2 \pi} \sqrt{g} \Phi \, \diff \phi \, \diff \theta}{\int_{0}^{2 \pi} \int_{0}^{2 \pi} \sqrt{g} \, \diff \phi \, \diff \theta}. \label{eq:flux_surface_avg}
\end{gather}

\section{Stationary linear perturbation of ideal MHD equilibrium}

For the intended application on stationary (compared to MHD mode eigenfrequencies) non-axisymmetric magnetic perturbations by external coils, we consider a perturbed ideal MHD equilibrium for pressure $p$, currents $\vec{J}$ and magnetic field $\vec{B}$ fulfilling
\begin{align}
  \grad p &= \frac{1}{c} \vec{J} \times \vec{B}, \label{eq:mhd-gen} \\
  \curl \vec{B} &= \frac{4 \pi}{c} \vec{J}, \label{eq:ampere-gen} \\
  \divg \vec{B} &= 0. \label{eq:divfree-gen}
\end{align}
Starting with a given MHD equilibrium fulfilling \cref{eq:mhd-gen,eq:divfree-gen} denoted by subscripts "$0$", linear order equations for an external magnetic perturbation (denoted by $\delta$) split into a vacuum and a plasma part (subscript $\text{v}$ and $\text{p}$, respectively) are
\begin{align}
  \grad \delta p &= \frac{1}{c} \left( \vec{J}_{0} \times \Bpert + \delta \vec{J} \times \vec{B}_{0} \right), \label{eq:mhd} \\
  \Bpert &= \Bvac + \Bplas, \\
  \Bvac &= \frac{1}{c} \oint \frac{I_{\text{c}}(\vec{r}') \, \diff \vec{l}' \times \vec{r}}{\lvert \vec{r} - \vec{r}' \rvert^{3}}, \label{eq:biot-savart} \\
  \Bplas &= \curl \delta \vec{A}, \\
  \curl (\curl \delta \vec{A}) &= \frac{4 \pi}{c} \delta \vec{J}, \label{eq:ampere} \\
  \Rightarrow \divg \Bpert &= \divg \delta \vec{J} = 0. \label{eq:divfree}
\end{align}
Here the perturbation field in vacuum, $\Bvac$, is pre-evaluated by a \textsc{Biot}--\textsc{Savart} integral over external\footnote{i.e.\ entirely outside the plasma region} coil currents $I_{\text{c}} (\vec{r}')$. This induces a plasma response, resulting in the current density perturbation $\delta \vec{J}$. The perturbation field from currents within the plasma, $\Bplas$, is in turn computed from $\delta \vec{J}$, again giving rise to a plasma response current. Now, the linearized force balance \cref{eq:mhd} is used to compute $\delta \vec{J}$ for given $\Bpert$ whereas \cref{eq:ampere} yields $\Bplas$ for given $\delta \vec{J}$.

The solution of \cref{eq:mhd} can further be split into two steps: First the pressure perturbation $\delta p$ is found, and then the plasma current density $\delta \vec{J}$ is computed using the condition $\divg \delta \vec{J} = 0$. For an unperturbed equilibrium with nested flux surfaces, both steps can be performed in a radially local manner if a field-aligned computational grid is used, which will become clear in the following sections. Radial coupling happens by the combination of the two individual steps since their effective radial locations of computation are shifted by a half-step in radial grid distance.

\Cref{eq:mhd} and \cref{eq:ampere} are solved in an alternating way until convergence is reached, as described in \cref{sec:iteration}. In addition a preconditioner is used to enhance convergence, which is discussed in \cref{sec:Arnoldi}. This approach is also used by \cite{Albert16}.

\subsection{Iteration scheme}
\label{sec:iteration}

From \cref{eq:mhd}, we calculate the current perturbation\footnote{and in an intermediate step, the pressure perturbation} from a given magnetic field perturbation. This can be done with kinetic code (e.g. NEO-2) or with MHD, as is discussed in \cref{sec:linmhd}. In either case, the computation can be written in compact form,
\begin{gather}
  \delta \vec{J} = \hat{P} \Bpert = \hat{P} \left ( \Bvac + \Bplas \right ), \label{eq:P_operator}
\end{gather}
with an abstract operator $\hat{P}$ representing the computation. It acts on the full magnetic perturbation, that is the contribution from the vacuum field $\Bvac$ produced by external coils and the plasma response field $\Bplas$.

From a given current perturbation, \cref{eq:ampere} is used to compute the plasma response field $\Bplas$. This kind of problem is commonly solved with a finite element method, as described in \cref{sec:compute_Bn}. In a similar manner as before, the operator $\hat{M}$ represents this calculation step:
\begin{gather}
  \Bplas = \hat{M} \delta \vec{J}. \label{eq:M_operator}
\end{gather}
Since only the current enclosed in the plasma volume is taken into account, only the plasma response field $\Bplas$ is affected. The external coils whose current produces the vacuum perturbation $\Bvac$ are assumed to have infinite impedance so that feedback from the plasma response can be neglected. $\Bvac$ is essentially fixed by \cref{eq:biot-savart}.

Substituting $\delta \vec{J}$ from \cref{eq:P_operator} in \cref{eq:M_operator} and using a shorthand $\hat{K} = \hat{M} \hat{P}$ gives
\begin{align}
  \hat{K} \left ( \Bvac + \Bplas \right ) &= \Bplas, \label{eq:K_fixed-point} \\
  \hat{K} \Bvac &= \left ( \hat{1} - \hat{K} \right ) \Bplas, \\
  \left ( \hat{1} - \hat{K} \right )^{-1} \hat{K} \Bvac &= \Bplas.
\end{align}
The first term can be rewritten in the form of a \textsc{Neumann} series, a generalisation of geometric series to operators, assuming the series converges:
\begin{gather}
  \left ( \hat{1} - \hat{K} \right )^{-1} = \sum_{k = 0}^{\infty} \hat{K}^{k}. \label{eq:Neumann_series}
\end{gather}
This way a consistent solution for $\Bplas$ can be computed from $\Bvac$ by repeated application of $\hat{K}$, given explicitly by the infinite series
\begin{gather}
  \Bplas = \left ( \hat{1} + \hat{K} + \hat{K}^{2} + \dotsb \right ) \hat{K} \Bvac = \sum_{k = 1}^{\infty} \hat{K}^{k} \Bvac = \sum_{k = 1}^{\infty} \Bpert^{(k)}. \label{eq:K_series}
\end{gather}
In \cref{eq:K_series} each term is given by the recurrence relation
\begin{gather}
  \Bpert^{(k+1)} = \hat{K} \Bpert^{(k)}.
\end{gather}
Adding the vacuum field as the initial value,
\begin{gather}
  \Bpert^{(0)} = \Bvac
\end{gather}
the series' terms are accumulated for the self-consistent solution:
\begin{gather}
  \Bpert = \sum_{k = 0}^{\infty} \Bpert^{(k)}.
\end{gather}
Alternatively, \cref{eq:K_fixed-point} can be expanded,
\begin{gather}
  \Bplas = \hat{K} \left ( \Bvac + \Bplas \right ) = \hat{K} \left ( \Bvac + \hat{K} \left ( \Bvac + \Bplas \right ) \right ) = \dotsb,
\end{gather}
yielding a fixed-point iteration for $\Bpert$:
\begin{gather}
  \Bpert^{[k+1]} = \hat{K} \Bpert^{[k]} + \Bvac.
\end{gather}
Compared to the previous approach, this one is cumulative, i.e. it immediately produces the next approximation of the full perturbation. In other words, it corresponds to the sequence of partial sums of the previous infinite series:
\begin{gather}
  \Bpert^{[n]} = \sum_{k = 0}^{n} \Bpert^{(k)}. \label{eq:K_partial_sum}
\end{gather}
For this to be consistent, the initial value is also given by the vacuum field,
\begin{gather}
  \Bpert^{[0]} = \Bvac.
\end{gather}
For illustration, both approaches are compared side-by-side in \cref{tab:comp_iter}.
\begin{table}[bth]
  \caption{Comparison of iteration with series (non-cumulative) and sequence (cumulative)}
  \label{tab:comp_iter}
  \begin{align*}
    \text{iteration step:} && \Bpert^{(k)} &= \hat{K} \Bpert^{(k-1)} & \Bpert^{[k]} &= \hat{K} \Bpert^{[k-1]} + \Bvac, \\
    \text{initial value:} && \Bpert^{(0)} &= \Bvac & \Bpert^{[0]} &= \Bvac, \\
    \text{step 1:} && \Bpert^{(1)} &= \hat{K} \Bpert^{(0)} = \hat{K} \Bvac & \Bpert^{[1]} &= \hat{K} \Bpert^{[0]} + \Bvac = \hat{K} \Bvac + \Bvac, \\
    \text{step 2:} && \Bpert^{(2)} &= \hat{K} \Bpert^{(1)} = \hat{K}^{2} \Bvac & \Bpert^{[2]} &= \hat{K} \Bpert^{[1]} + \Bvac = \left ( \hat{K}^{2} + \hat{K} + \hat{I} \right ) \Bvac, \\
    \text{explicit form:} && \Bpert^{(n)} &= \hat{K}^{n} \Bvac & \Bpert^{[n]} &= \sum_{k = 0}^{n} \hat{K}^{k} \Bvac, \\
    \text{full perturbation:} && \Bpert &= \sum_{k = 0}^{\infty} \hat{K}^{n} \Bvac & \Bpert &= \Bpert^{[\infty]}, \\
    \text{full plasma response:} && \Bplas &= \sum_{k = 1}^{\infty} \hat{K}^{n} \Bvac & \Bplas &= \Bpert^{[\infty]} - \Bvac.
  \end{align*}
\end{table}
For the implementation of preconditioned iterations (see \cref{sec:Arnoldi}), the cumulative approach is more convenient. To reproduce the intermediate summands, we use \cref{eq:K_partial_sum} and arrive at
\begin{gather}
  \Bpert^{(k)} = \Bpert^{[k]} - \Bpert^{[k-1]}.
\end{gather}

\subsection{Enhanced convergence with preconditioned iterations}
\label{sec:Arnoldi}

Both approaches outlined in \cref{sec:iteration} hinge on the convergence of the \textsc{Neumann} series in \cref{eq:Neumann_series}. The convergence criterion for the similar geometric series of scalars is not directly applicable to operators, but to their corresponding spectrum of eigenvalues. Thus we shall now consider a discretized equation of finite dimension $N$.

We start from the fixed-point relation of the previous section which has the general form
\begin{gather}
  \vec{x} = \hat{K} \vec{x} + \vec{x}_{0}. \label{eq:Arnoldi_fixed_point}
\end{gather}
$\vec{x}$ serves as a shorthand for $\Bpert$ and a reminder that the derivations in this section are not just valid for the specific problem of calculating magnetic fields. Similarly, $\vec{x}_{0}$ stands in for $\Bvac$.  Assuming the linear operator $\hat{K}$ is non-singular, we can formally write down an eigendecomposition
\begin{gather}
  \hat{K} = \hat{V} \hat{\Lambda} \hat{V}^{-1},
\end{gather}
where $\hat{\Lambda}$ is a diagonal matrix with the eigenvalues,
\begin{gather}
  \hat{\Lambda} = \begin{pmatrix}
    \lambda_{1} & & & \\
    & \lambda_{2} & & \\
    & & \ddots & \\
    & & & \lambda_{N}
  \end{pmatrix} = \vec{\lambda} \hat{I},
\end{gather}
$\hat{V}$ contains the corresponding eigenvectors as its columns,
\begin{gather}
  \hat{V} = \left ( \vec{v}_{1}, \vec{v}_{2}, \dotsc, \vec{v}_{N} \right ),
\end{gather}
and $\hat{V}^{-1}$ is the inverse of $\hat{V}$. $\vec{x}$ can then be expressed in the eigenbasis with components $x_{k}'$,
\begin{gather}
  \vec{x} = \sum_{k = 1}^{N} x_{k}' \vec{v}_{k} = \hat{V} \vec{x}',
\end{gather}
and transformed back to the original basis by the inverse,
\begin{gather}
  \vec{x}' = \hat{V}^{-1} \vec{x}.
\end{gather}
Rearranging \cref{eq:Arnoldi_fixed_point} to
\begin{gather}
  \left ( \hat{I} - \hat{K} \right ) \vec{x} = \vec{x}_{0}, \label{eq:Arnoldi_direct}
\end{gather}
multiplying from the left with $\hat{V}^{-1}$ and expanding in the eigenbasis yields
\begin{gather}
  \Bigl ( \underbrace{\hat{V}^{-1} \hat{I} \hat{V}}_{\hat{I}} - \hat{\Lambda} \Bigr ) \vec{x}' = \vec{x}_{0}'.
\end{gather}
Solving for $\vec{x}'$ gives
\begin{gather}
  \vec{x}' = \left ( \hat{I} - \hat{\Lambda} \right )^{-1} \vec{x}_{0}' = \begin{pmatrix}
    \frac{1}{1 - \lambda_{1}} & & & \\
    & \frac{1}{1 - \lambda_{2}} & & \\
    & & \ddots & \\
    & & & \frac{1}{1 - \lambda_{N}}
  \end{pmatrix} \begin{pmatrix} x_{01}' \\ x_{02}' \\ \vdots \\ x_{0N}' \end{pmatrix}, \label{eq:direct_inversion}
\end{gather}
which can then be transformed back to the original basis. This approach yields a solution without resorting to series expansion and associated considerations of convergence, instead inverting the matrix directly. However, full diagonalization of $\hat{K}$ is computationally expensive, but partial diagonalization can be used to enhance convergence, or permit convergence at all, as will be seen below.

Applying the eigendecomposition to the operator series, we see that repeated application of $\hat{K}$ simplifies to
\begin{gather}
  \hat{K}^{n} \vec{x}_{0} = \underbrace{\left ( \hat{V} \hat{\Lambda} \hat{V}^{-1} \right ) \left ( \hat{V} \hat{\Lambda} \hat{V}^{-1} \right ) \dotsb \left ( \hat{V} \hat{\Lambda} \hat{V}^{-1} \right )}_{k} \vec{x}_{0}= \hat{V} \hat{\Lambda}^{n} \hat{V}^{-1} \vec{x}_{0} = \hat{V} \hat{\Lambda}^{n} \vec{x}_{0}' = \sum_{k = 1}^{N} \lambda_{k}^{n} x_{0 k}' \vec{v}_{k}.
\end{gather}
Comparing this to the solution in \cref{eq:direct_inversion}, it becomes apparent that convergence of the \textsc{Neumann} operator series is equivalent to the convergence of the geometric series of all eigenvalues. Since the geometric series only converges for $\lvert \lambda_{k} \rvert < 1$ (and only reasonably fast for $\lvert \lambda_{k} \rvert \ll 1$), we need direct inversion for the largest eigenvalues, i.e.\ partial diagonalization. To find the largest eigenvalues, we use the \textsc{Arnoldi} method summarized in \cref{app:Arnoldi}. This is a \textsc{Krylov} subspace method that reduces to the \textsc{Lanczos} method for Hermitian matrices and is also used as part of the generalized minimal residual method (GMRES). It does not involve matrix-matrix multiplication but only matrix-vector multiplication. Thus the linear operator needs not be given explicitly in matrix form, only its action on a given vector, which is fulfilled in our case for $\hat{K}$.

Using the \textsc{Arnoldi} method will give us good approximations to the largest $r$ eigenvalues, denoted as $\vec{\lambda}_{r}$ or equivalently $\hat{\Lambda}_{r}$ and commonly called \textsc{Ritz} eigenvalues, as well as an orthonormal set of associated eigenvectors, this time arranged in an $N \times r$ matrix $\hat{V}_{r}$. The latter span the \textsc{Krylov} subspace of the full eigenspace. Instead of the eigenvalue equation of full rank,
\begin{gather}
  \hat{K} \vec{v}_{k} = \lambda_{k} \vec{v}_{k} \quad \forall k = 1, 2, \dotsc, N,
\end{gather}
or equivalently,
\begin{gather}
  \hat{K} \hat{V} = \vec{\lambda} \hat{V} = \hat{V} \hat{\Lambda},
\end{gather}
we can write down the reduced eigenvalue equation in the \textsc{Krylov} subspace,
\begin{gather}
  \hat{K} \hat{V}_{r} = \vec{\lambda}_{r} \hat{V}_{r} = \hat{V}_{r} \hat{\Lambda}_{r}. \label{eq:reduced_eigvals}
\end{gather}
Note that, compared to the eigenvalue equation in full space, the $r \times r$ matrix $\hat{\Lambda}_{r}$ has to be to the right of the $N \times r$ matrix $\hat{V}_{r}$.

With the largest $r$ eigenvalues now known, we want to find a preconditioner that modifies the direct iteration step in \cref{eq:Arnoldi_fixed_point} so that the largest eigenvalues don't contribute. Usually this is written by left-multiplying \cref{eq:Arnoldi_direct} by the inverse of a full-rank linear operator:
\begin{gather}
  \hat{\Pi}^{-1} \left ( \hat{I} - \hat{K} \right ) \vec{x} = \hat{\Pi}^{-1} \vec{x}_{0}. \label{eq:precon}
\end{gather}
We choose
\begin{gather}
  \hat{\Pi}^{-1} = \hat{I} - \hat{A}
\end{gather}
with some general matrix $\hat{A}$. \Cref{eq:precon} then becomes
\begin{gather}
  \left ( \hat{I} - \hat{A} - \left ( \hat{I} - \hat{A} \right ) \hat{K} \right ) \vec{x} = \left ( \hat{I} - \hat{A} \right ) \vec{x}_{0},
\end{gather}
which can be rearranged to resemble \cref{eq:Arnoldi_direct},
\begin{gather}
  \left ( \hat{I} - \hat{\bar{K}} \right ) \vec{x} = \bar{\vec{x}}_{0},
\end{gather}
with a modified iteration step
\begin{gather}
  \hat{\bar{K}} = \hat{A} + \left ( \hat{I} - \hat{A} \right ) \hat{K} \label{eq:Kbar}
\end{gather}
and a modified initial value
\begin{gather}
  \bar{\vec{x}}_{0} = \left ( \hat{I} - \hat{A} \right ) \vec{x}_{0}.
\end{gather}
By analogy, we can then write the explicit preconditioned iteration step as
\begin{gather}
  \bar{\vec{x}}^{[k+1]} = \hat{\bar{K}} \bar{\vec{x}}^{[k]} + \bar{\vec{x}}_{0}.
\end{gather}
Replacing the modified quantities on the right-hand side according to their definitions and rearranging gives
\begin{gather}
  \bar{\vec{x}}^{[k+1]} = \hat{A} \bar{\vec{x}}^{[k]} + \left ( \hat{I} - \hat{A} \right ) \left ( \hat{K} \bar{\vec{x}}^{[k]} + \vec{x}_{0} \right ).
\end{gather}
Now the last term in parentheses reproduces the direct, unmodified iteration yielding an unmodified $\vec{x}^{[k+1]}$,
\begin{gather}
  \bar{\vec{x}}^{[k+1]} = \hat{A} \bar{\vec{x}}^{[k]} + \left ( \hat{I} - \hat{A} \right ) \vec{x}^{[k+1]},
\end{gather}
which can again be rearranged for a final result,
\begin{gather}
  \bar{\vec{x}}^{[k+1]} = \vec{x}^{[k+1]} - \hat{A} \left ( \vec{x}^{[k+1]} - \bar{\vec{x}}^{[k]} \right ).
\end{gather}
Compared to the direct iterations, only one additional matrix-vector multiplication is necessary, but see below for details.

Now all we need is to compute $\hat{A}$. We required that the largest $r$ eigenvalues don't contribute to iterations, so we demand
\begin{gather}
  \hat{\bar{K}} \vec{v}_{k} \overset{!}{=} \vec{0} \quad \forall k \le r.
\end{gather}
This can be compactly rewritten and expanded via \cref{eq:Kbar,eq:reduced_eigvals} to give
\begin{gather}
  \hat{\bar{K}} \hat{V}_{r} = \hat{A} \hat{V}_{r} + \left ( \hat{I} - \hat{A} \right ) \hat{K} \hat{V}_{r} = \hat{A} \hat{V}_{r} + \left ( \hat{I} - \hat{A} \right ) \hat{V}_{r} \hat{\Lambda}_{r} \overset{!}{=} \hat{0}.
\end{gather}
This can in turn be rearranged to
\begin{gather}
  \hat{A} \hat{V}_{r} \left ( \hat{\Lambda}_{r} - \hat{I} \right ) \overset{!}{=} \hat{V}_{r} \hat{\Lambda}_{r}.
\end{gather}
Right-multiplying with the inverse of $\hat{\Lambda}_{r} - \hat{I}$ yields
\begin{gather}
  \hat{A} \hat{V}_{r} \overset{!}{=} \hat{V}_{r} \hat{\Lambda}_{r} \left ( \hat{\Lambda}_{r} - \hat{I} \right )^{-1}.
\end{gather}
Now $\hat{V}_{r}$ is not square and thus cannot be inverted, but we can add a unity term on the right-hand side:
\begin{gather}
  \hat{A} \hat{V}_{r} \overset{!}{=} \hat{V}_{r} \hat{\Lambda}_{r} \left ( \hat{\Lambda}_{r} - \hat{I} \right )^{-1} \left ( \hat{V}_{r}^{\dagger} \hat{V}_{r} \right )^{-1} \hat{V}_{r}^{\dagger} \hat{V}_{r}.
\end{gather}
By direct comparison it can be seen that a solution is given by
\begin{gather}
  \hat{A} \equiv \hat{V}_{r} \hat{\Lambda}_{r} \left ( \hat{\Lambda}_{r} - \hat{I} \right )^{-1} \left ( \hat{V}_{r}^{\dagger} \hat{V}_{r} \right )^{-1} \hat{V}_{r}^{\dagger}.
\end{gather}
The inner part can be grouped to the inverse of an $r \times r$ matrix $\hat{L}_{r}$,
\begin{gather}
  \hat{L}_{r} = \hat{V}_{r}^{\dagger} \hat{V}_{r} \left ( \hat{\Lambda}_{r} - \hat{I} \right ).
\end{gather}
This can then be conveniently inverted using the LAPACK routine \texttt{zgesv} to solve for $\hat{Y}$ in
\begin{gather}
  \hat{L}_{r} \hat{Y} = \hat{I}.
\end{gather}
Since $\hat{A}$ is constant during iterations, these computations would only need to be done once before preconditioned iterations start. Note that in practice though, $\hat{A}$ is not stored explicitly, since $r \ll N$ -- in test runs, $r \approx \num{1e1}, N \approx \num{1e5}$. Instead of keeping $N^2$ entries of the dense matrix $\hat{A}$ in storage, we keep $N r$ entries of $\hat{V}_{r}$ and $r^2$ entries of $\hat{\Lambda}_{r} \hat{L}_{r}^{-1}$. Applying the matrices on a given $\vec{x}$ from right to left then requires additional matrix-vector multiplications, but in the worst case, this involves only $2 N r + r^2$ floating-point operations compared to $N^2$ for one matrix-vector multiplication with full $\hat{A}$. For an overview on matrix sizes, see \cref{tab:matrix_dimensions}.
\begin{longtable}{ll}
  \caption{Dimensions of quantities used in derivation of preconditioned iterations.}
  \label{tab:matrix_dimensions} \\
  \toprule
  Quantity & Dimension \\
  \midrule
  \endfirsthead
  \toprule
  Quantity & Dimension \\
  \midrule
  \endhead
  $\vec{x}$ & $N$ \\
  $\vec{\lambda}_{r}$ & $r$ \\
  $\vec{v}_{k}$ & $N$ \\
  $\hat{\Lambda}_{r}$ & $r \times r$ \\
  $\hat{V}_{r}$ & $N \times r$ \\
  $\hat{V}_{r}^{\dagger}$ & $r \times N$ \\
  $\hat{A}$ & $N \times N$ \\
  $\hat{L}_{r}$ & $r \times r$ \\
  \bottomrule
\end{longtable}
It should be noted that the approximation error of the \textsc{Ritz} eigenvalues relative to the true eigenvalues decreases with the size of the \textsc{Krylov} subspace. This means that more \textsc{Arnoldi} iterations should be completed than is purely necessary for the expected number of eigenvalues with absolute value below a given threshold. Even if most of them are not used in the preconditioner, without sufficient accurcy in the largest eigenvalues the preconditioner will fail to assure convergence. As a rule of thumb, there should be \numrange{2}{3} times as many \textsc{Arnoldi} iterations as there are \textsc{Ritz} eigenvalues used with the preconditioner.

\clearpage
\section{Geometrical considerations}

Even when the magnetic field is not axisymmetric, the axisymmetry of the tokamak device carries over to the computational domain. It stands to reason to take the periodicity in the symmetry direction, i.e. the cylindrical angle $\phi$, into account. The non-axisymmetric magnetic perturbation field in cylindrical coordinates $(R, \phi, Z)$ can then be expanded as a \textsc{Fourier} series:
\begin{gather}
  \Bpert (R, \phi, Z) = \sum_{n = -\infty}^{\infty} \vec{B}_{n} (R, Z) \e^{\im n \phi}
\end{gather}
Note that only the component functions are transformed; the basis vectors which generally depend on the transformation variable are unaffected. This means $\Bpert$ and $\vec{B}_{n}$ share the same geometrical basis.

As all equations are linear, a superposition of multiple harmonics is easily possible. Here we limit the analysis to an axisymmetric unperturbed equilibrium and a single toroidal perturbation harmonic
\begin{gather}
  \Bpert = \Real (\vec{B}_{n} \e^{\im n \phi})
\end{gather}
with fixed $n$ and a similar notation for other perturbed quantities. Note that $n \neq 0$; such a perturbation is necessarily small and considered part of the axisymmetric equilibrium. Thus an index $0$ unambiguously refers to equilibrium quantities. This choice and further conventions are also listed in \cref{tab:decorations}.

In axisymmetric coordinate systems, such as the aforementioned cylindrical system $(R, \phi, Z)$, \cref{eq:mhd,eq:divfree} are to be solved for harmonics in the toroidal angle $\phi$:
\begin{align}
  \grad p_{n} + \im n p_{n} \grad \phi &= \frac{1}{c} \left( \vec{J}_{0} \times \vec{B}_{n} + \vec{J}_{n} \times \vec{B}_{0} \right), \label{eq:mhd-phi} \\
  \divg \vec{J}_{n}^{\pol}+ \im n J_{n}^{\phi} &= 0. \label{eq:divfree-phi}
\end{align}
now with a 2D $\grad$ operator acting in the poloidal ($RZ$) plane. The explicit definition depends on the coordinate system used and is outlined in \cref{sec:cocos}.

\subsection{Coordinate conventions}
\label{sec:cocos}

We generally follow the notational convention of \textcite{dHaeseleer91}, which will be succinctly summarized in this section. When using curvilinear coordinates in three-dimensional Euclidean space, two complementary vector bases can be defined. Using coordinates $u^{1}, u^{2}, u^{3}$, the basis vectors $\vec{e}_{1}, \vec{e}_{2}, \vec{e}_{3}$ are defined as tangent-basis vectors, which means they follow the coordinate curves at a given point $\vec{R}$:
\begin{gather}
  \vec{e}_{k} (\vec{R}) = \pd[\vec{R}]{u^{k}}, \quad k = 1, 2, 3.
\end{gather}
This means that the corresponding coordinate $u^{k}$ is varied while the other two are held constant. Alternatively, the direction of a basis vector may be defined as normal vector on the associated coordinate surface, i.e. where $u^{k}$ is held constant and the other two coordinates are varied. These reciprocal basis vectores are then related to the gradient:
\begin{gather}
  \vec{e}^{k} (\vec{R}) = \grad u^{k} (\vec{R}), \quad k = 1, 2, 3.
\end{gather}
Note that with this definition, neither basis set is necessarily normalized or even orthogonal. They are however pairwise orthonormal by definition, so that
\begin{gather}
  \vec{e}_{i} \cdot \vec{e}^{j} = \delta_{i}^{j},
\end{gather}
where the indices are kept in the same position with the \textsc{Kronecker} delta. As a consequence, the following relations between basis vectors are also given, where $\varepsilon_{ijk} = 1$:
\begin{gather}
  \vec{e}_{i} = \frac{\vec{e}^{j} \times \vec{e}^{k}}{\vec{e}^{i} \cdot (\vec{e}^{j} \times \vec{e}^{k})}, \quad \vec{e}^{i} = \frac{\vec{e}_{j} \times \vec{e}_{k}}{\vec{e}_{i} \cdot (\vec{e}_{j} \times \vec{e}_{k})}.
\end{gather}
An abstract vector $\vec{v}$ can be expanded in either basis, using the \textsc{Einstein} summation convention:
\begin{gather}
  \vec{v} = (\vec{v} \cdot \vec{e}^{k}) \vec{e}_{k} = v^{k} \vec{e}_{k}, \quad \vec{v} = (\vec{v} \cdot \vec{e}_{k}) \vec{e}^{k} = v_{k} \vec{e}^{k}.
\end{gather}
In the first case using tangent-basis vectors, the component $v^{k}$ is called the contravariant component. In the second case using reciprocal basis vectors, the component $v_{k}$ is called the covariant component. Conversion between the two bases is accomplished via the components of the metric tensor $\symsf{g}$,
\begin{gather}
  v_{i} = g_{ij} v^{j}, \quad v^{i} = g^{ij} v_{j},
\end{gather}
where the summation convention is implicit and the metric tensor components are defined as
\begin{gather}
  g_{ij} = \vec{e}_{i} \cdot \vec{e}_{j}, \quad g^{ij} = \vec{e}^{i} \cdot \vec{e}^{j}.
\end{gather}
The determinant $g = \det \symsf{g}$ of the metric tensor appears further in the following vector calculations and is related to the Jacobian $J$ of the coordinate system defined by the $u^{k}$, again with $\varepsilon_{ijk} = 1$:
\begin{gather}
  J = \sqrt{g} = \sqrt{\det \symsf{g}} = \vec{e}_{i} \cdot (\vec{e}_{j} \times \vec{e}_{k}).
\end{gather}
With the nabla operator represented as
\begin{gather}
  \nabla = \vec{e}^{k} \pd{u^{k}},
\end{gather}
the gradient follows:
\begin{gather}
  \grad f = \pd[f]{u^{k}} \vec{e}^{k}.
\end{gather}
The divergence is most simply defined in terms of contravariant components,
\begin{gather}
  \divg \vec{v} = \frac{1}{\sqrt{g}} \pd{u^{k}} (\sqrt{g} v^{k}),
\end{gather}
while the curl in its simplest form uses covariant components and returns contravariant components:
\begin{gather}
  \curl \vec{v} = \frac{\varepsilon_{ijk}}{\sqrt{g}} \pd[v_{j}]{u^{i}} \vec{e}_{k}.
\end{gather}
On occasion, parallel or perpendicular components with respect to the magnetic field $\vec{B}$ are needed:
\begin{gather}
  \vec{v}^{\parallel} = (\vec{v} \cdot \hat{\vec{B}}) \hat{\vec{B}} = (\vec{v} \cdot \vec{h}) \vec{h}, \\
  \vec{v}^{\perp} = -\hat{\vec{B}} \times (\hat{\vec{B}} \times \vec{v}) = -\vec{h} \times (\vec{h} \times \vec{v}).
\end{gather}
Here, $\hat{\vec{B}}$ denotes the unit vector of $\vec{B}$, but in the special case of the magnetic field, $\vec{h}$ may be used as well.

With these conventions set forth, we can define the necessary coordinate systems. We use two different right-handed coordinate systems, one cylindrical and one pseudotoroidal. As cylindrical coordinates we use $(R, \phi, Z)$ with $\phi$ running counterclockwise as seen from above, so
\begin{gather}
  x = R \cos \phi, \quad y = R \sin \phi, \quad z = Z.
\end{gather}
These coordinates are used in computations and for meshes. They are orthogonal, as can be seen from the metric tensor, which is given by
\begin{gather}
  \symsf{g} = \begin{pmatrix}
    1 & 0 & 0 \\
    0 & R^{2} & 0 \\
    0 & 0 & 1
  \end{pmatrix}.
\end{gather}
In general curvilinear coordinates, different basis vectors and vector components can have different physical dimensions depending on the coordinates used. Especially when dealing with numerical data, it would be desirable to use a representation with the \enquote{right} units and a normalized basis. In the given cylindrical coordinates, $\vec{e}_{R}$ and $\vec{e}_{Z}$ are normalized and equal to $\vec{e}^{R}$ and $\vec{e}^{Z}$ respectively, as are the corresponding components. In Cartesian coordinates, the basis vectors in toroidal direction are given by
\begin{gather}
  \vec{e}_{\phi} = R \cos \phi \, \vec{e}_{x} + R \sin \phi \, \vec{e}_{y}, \quad \vec{e}^{\phi} = \frac{1}{R} \cos \phi \, \vec{e}_{x} + \frac{1}{R} \sin \phi \, \vec{e}_{y}.
\end{gather}
These point in the same direction and are easily normalized. Taking into account these dimensions of the basis vectors, we can write the physical toroidal component as
\begin{gather}
  B_{(\phi)} = \frac{1}{R} B_{\phi} = R B^{\phi}, \label{eq:physical_phi}
\end{gather}
where the parentheses signify that it is the physical component and not the covariant component. Note that \cref{eq:physical_phi} is not necessarily true in other coordinate systems using the $\phi$ coordinate because $\vec{e}^{\phi}$ and $\vec{e}_{\phi}$ might not point in the same direction.

In regards to this coordinate system, the experimental setup can be characterized. When viewing the poloidal plane, $B_{0 (\phi)}$ points in the negative $\phi$ direction, the plasma current $I_{\text{p}}$ points in the positive $\phi$ direction and the poloidal field $\vec{B}_{0}^{\pol}$ is going in the clockwise direction. Poloidal-toroidal decomposition of the equilibrium field $\vec{B}_{0}$ then yields the representation
\begin{gather}
  \vec{B}_{0} = \vec{B}_{0}^{\pol} + \vec{B}_{0}^{\tor}, \label{eq:B_pol_tor}
\end{gather}
where 
\begin{align}
  \vec{B}_{0}^{\pol} &= \grad \psi \times \grad \phi, \label{eq:B_pol} \\
  \vec{B}_{0}^{\tor} &= B_{0 \phi} \grad \phi. \label{eq:B_tor}
\end{align}
Here, $\psi$ is the normalized \emph{disc} poloidal flux, i.e.
\begin{gather}
  \psi = \frac{1}{2 \pi} \Psi_{\pol} = \frac{1}{2 \pi} \int \vec{B}_{0} \cdot \diff \vec{S},
\end{gather}
where $\vec{S}$ is the disc that at a point of evaluation $(R_{S}, Z_{S})$ is given by $R \leq R_{S}, Z = Z_{S}$. The orientation of $\vec{S}$ fixes the sign\footnote{Since $\vec{B}_{0}$ is not defined outside the plasma volume and only $\grad \psi$ enters calculations, $\psi$ is defined up to a constant and thus could be shifted to change sign. However, the sign of $\grad \psi$ is fixed.} of $\psi$. Here, $\psi$ is expected to increase towards the magnetic axis -- $\psi_{\text{min}}$ is located at the outermost flux surface and $\psi_{\text{max}}$ is located at the magnetic axis. This leads to the following contravariant components for $\vec{B}_{0}^{\pol}$ in cylindrical coordinates:
\begin{align}
  B_{0}^{R} &= (\grad \psi \times \grad \phi)^{R} = -\frac{1}{R} \pd[\psi]{Z}, \\
  B_{0}^{Z} &= (\grad \psi \times \grad \phi)^{Z} = \frac{1}{R} \pd[\psi]{R}.
\end{align}
Note that the toroidal field coils produce a magnetic field that is roughly proportional to $\frac{1}{R}$, so $B_{0 \phi}$ is assumed to be constant over the entire plasma volume.

The second set of coordinates represent a distorted pseudotoroidal system used as symmetry flux coordinates for derivations in \cref{sec:j0phi,sec:nonres}. Keeping the toroidal angle $\phi$, the poloidal plane is spanned by a pseudoradial \emph{flux surface label} $\rho$ centered at the magnetic axis and a poloidal angle $\theta$. While it is common to use $\psi$ as the flux surface label, for derivations we keep the more intuitive notation of \textcite{dHaeseleer91} where $\rho$ is increasing towards the outside of the torus, i.e. $\rho = -\psi$. With $\theta$ pointing in the counter-clockwise direction, $(\rho, \phi, \theta)$ constitutes a right-hand system. While this deviates from \textcite{dHaeseleer91}, where $\zeta = \frac{\pi}{2} - \phi$ is used instead, it is consistent with the COCOS~3 convention of \textcite{Sauter13}, where an overview of possible combinations of coordinates are considered along with conversion between these choices and a procedure to check the consistency. As a consequence, the safety factor $q$ is positive and one of a few equivalent definitons is
\begin{gather}
  q = \frac{B_{0}^{\phi}}{B_{0}^{\theta}}. \label{eq:q_field_line_pitch}
\end{gather}
The sign of $q$ describes the sign of the helicity in $(\phi, \theta)$ and can be explicitly computed as described in \cref{sec:safety_factor}. The Jacobian of symmetry flux coordinates $(\rho, \phi, \theta)$ is
\begin{gather}
  \sqrt{g} = \frac{-1}{B_{0}^{\theta}} = -\frac{q}{B_{0}^{\phi}} = -\frac{q R^{2}}{B_{0 \phi}}. \label{eq:flux_metric}
\end{gather}
The change of sign in comparison to \textcite{dHaeseleer91} is due to the reversed toroidal angle. This way, $\sqrt{g}$ is still positive.

\subsection{Discretization and local coordinate system}
\label{sec:grid}

So far, we have given a fairly general description of the problem without explicit refernce to numerical methods, apart maybe from the iteration scheme in \cref{sec:iteration}. One necessary modification is the discretization of the problem. The finite element method outlined in \cref{sec:compute_Bn} uses a discretization of the computational domain, i.e. it introduces a triangular grid. While other tilings are possible, triangulation is the simplest and for triangles, the \textsc{Delaunay} algorithm is unique. The latter maximizes the triangles' minimal interior angle, which is desirable because a more elongated triangle shape reduces the quality of approximations on it. However, we choose to align the grid on flux surfaces in order to use the associated special properties.

A set of nested flux surfaces is chosen, e.g. a number $n_{\text{flux}}$ of curves of constant $\psi$ which are equidistant between the magnetic Axis and the X point. These are then intersected by rays originating from the magnetic axis. Note that these rays are not curves of constant $\theta$, as these are generally not straight in $(R, Z)$ coordinates. As a result, between any two flux surfaces there is a \emph{ring} or \emph{strip} of quadrangles going around in poloidal direction. These quadrangles are then diagonally split into triangles, yielding two types of triangles. An exception is the innermost ring containing the magnetic axis, where there is only one type of triangle and no quadrangles to split. This kind of grid is depicted in \cref{fig:grid} where concentric circles are used to illustrate the nested flux surfaces.
\begin{figure}[bth]
  \centering
  \begin{subfigure}[b]{0.33\textwidth}
    \centering
    \input{grid0.tpx}
    \caption{The innermost loop of the grid with the magnetic axis at its center. Edge \fs\ lies on the flux surface in the infinitesimal limit.}
    \label{fig:grid0}
  \end{subfigure}
  \quad
  \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \input{grid1.tpx}
    \caption{One of the outer loops of the grid with two alternating kinds of triangles with edge \fs\ lying on the inner and outer flux surface respectively.}
    \label{fig:grid1}
  \end{subfigure}
  \caption{The 2D mesh is given by a triangulation of poloidal cross-sections of the nested flux surfaces, resulting in \enquote{loops}. The cross-sections are assumed to be circular for illustration purposes.}
  \label{fig:grid}
\end{figure}

For reasons that will become more apparent in \cref{sec:compute_currn,sec:nonres}, we use symbolic names instead of numbers to refer to edges and nodes. In the implementation, these names are mapped to their numerical index (see \cref{sec:inputs}). The label \fs\ designates the edge that approximates the flux surface, i.e. it is parallel to the flux surface in the infinitesimal limit. The labels \inw\ and \out\ are chosen so that some flux is imagined to enter the triangle at edge \inw\ and exit at edge \out, again entering the next triangle through edge \inw\ and so on, going around the ring in poloidal direction. The nodes are labeled by the corresponding uppercase letter of the opposite edge. These labels are also annoted in \cref{fig:grid}. Note that the labels are necessarily local to each triangle.

Furthermore, for each edge we use a local orthogonal coordinate system on each triangle edge with $\vec{l}$ the vector of length $l$ along the edge in counter-clockwise orientation, $\vec{n}$ the outward normal of length $l$ and $\grad \phi$ pointing inside the plane. We obtain relations
\begin{align}
  \vec{l} \times \vec{n} &= l^{2} R \grad \phi, \label{eq:edge_phi} \\
  \vec{n} \times R \grad \phi &= \vec{l}, \label{eq:edge_l} \\
  R \grad \phi \times \vec{l} &= \vec{n}. \label{eq:edge_n}
\end{align}
This is illustrated for a small sector on one ring in \cref{fig:local_coordinates}.
\begin{figure}[bth]
  \centering
  \input{./local_coordinates.tikz}
  \caption{Schematic of the local coordinate system.}
  \label{fig:local_coordinates}
\end{figure}

Since edge \fs\ is approximated to lie on the flux surface, some properties carry over. In particular, since flux surfaces are surfaces of constant $\psi$ and $p_{0}$, we have
\begin{gather}
  \vec{n}_{\fs} \parallel \grad \psi \parallel \grad p_{0},
\end{gather}
as well as
\begin{gather}
  \vec{B}_{0} \cdot \vec{n}_{\fs} = 0, \quad \vec{J}_{0} \cdot \vec{n}_{\fs} = 0.
\end{gather}
Likewise, it should be noted that $\nabla \phi$ is perpendicular to all purely poloidal quantities which includes, apart from those designated with superscript \pol, all local coordinate vectors $\vec{l}$ and $\vec{n}$, \textsc{Fourier} components with subscript $n$, as well as $\grad \psi$ and $\grad p_{0}$.

\subsection{Representation of fields on the grid}
\label{sec:dofs}

Another approximation made in the finite element method is the choice of a \emph{basis} to represent a scalar or vector field locally on one element of the grid. Scalar fields like the pressure perturbation can be approximated with \textsc{Lagrange} elements of the lowest order where the \emph{degrees of freedom} are the values on the nodes and any value within the triangle is interpolated from the values of its nodes. Many other choices are available, but this is the simplest option to implement and it is sufficient for our needs. For vector fields some more considerations are necessary; see \cref{sec:compute_Bn} for more details. We are mostly interested in representation of the magnetic flux density and the current density, both of which characteristically show zero divergence. Thus it is necessary to choose a basis that yields a well-defined convergence. This is guaranteed by \textsc{Raviart}--\textsc{Thomas} elements, where in the lowest-order case, the degrees of freedom are the fluxes of the vector field across the triangle edges:
\begin{gather}
  \Psi_{k} = \int_{\Gamma_{k}} R \vec{B}_{n}^{\pol} \cdot \hat{\vec{n}} \, \diff l \approx R (\Gamma_{k}) \vec{B}_{n}^{\pol} (\Gamma_{k}) \cdot \vec{n}_{k}, \label{eq:Psi_k} \\
  I_{k} = \int_{\Gamma_{k}} R \vec{J}_{n}^{\pol} \cdot \hat{\vec{n}} \, \diff l \approx R (\Gamma_{k}) \vec{J}_{n}^{\pol} (\Gamma_{k}) \cdot \vec{n}_{k}. \label{eq:I_k}
\end{gather}
There are a few things to note here. Firstly, the factor $R$ is included due to the metric in cylindrical coordinates and the fact that the integrand derives from the divergence theorem. Secondly, $\hat{\vec{n}}$ is normalized, but $\vec{n}$ is not, so the length of the edge is included as a factor. Lastly, the integral is approximated by evaluation at only a single point, the edge midpoint $\Gamma_{k}$. Conversely, to interpolate the value at given point $\vec{r}$ within a triangle, each degree of freedom $\Psi_{k}$ or $I_{k}$ is multiplied by the vectorial basis formed by the vector connecting $\vec{r}$ and the node opposing edge $k$, weighted with the triangle area $S_{\Omega}$:
\begin{gather}
  \vec{B}_{n} (\vec{r}) = \frac{\Psi_{\fs} (\vec{r} - \vec{r}_{\vfs}) + \Psi_{\inw} (\vec{r} - \vec{r}_{\vinw}) + \Psi_{\out} (\vec{r} - \vec{r}_{\vout})}{2 S_{\Omega}}, \\
  \vec{J}_{n} (\vec{r}) = \frac{I_{\fs} (\vec{r} - \vec{r}_{\vfs}) + I_{\inw} (\vec{r} - \vec{r}_{\vinw}) + I_{\out} (\vec{r} - \vec{r}_{\vout})}{2 S_{\Omega}},
\end{gather}
Note that the value is well-defined only within the triangle but not on the edge: while the flux across the edge, i.e. the normal component of the field is consistent with the neighbouring triangle, the component \emph{along} the edge is not necessarily continuous across triangles.

On a general note, we indicate the point of evaluation in parentheses after the field in question: $\vec{r}$ refers to a node, as in $p_{n} (\vec{r})$, $\Gamma_{k}$ refers to the midpoint of edge $k$, as in $p_{n} (\Gamma_{k})$ or $\vec{B}_{n} (\Gamma_{k})$, and $\Omega$ refers to a \enquote{shifted centroid}, as in $p_{n} (\Omega)$ or $\vec{B}_{n} (\Omega)$. This shifted centroid is calculated by assigning double weight to node $\vfs$, i.e. $\left ( \frac{1}{2}, \frac{1}{4}, \frac{1}{4} \right )$ in barycentric coordinates where the first coordinate is defined relative to node $\vfs$. This assures that this shifted centroid is halfway between flux surfaces, as the actual centroid is closer to the flux surface on which nodes $\vinw$ and $\vout$ lie, thus alternating between the two flux surfaces from one triangle to the next. To get an idea of this behaviour, refer to \cref{fig:local_coordinates}, where the $\otimes$ symbols indicating the $\grad \phi$ basis vectors are placed at these shifted centroids.

Furthermore, toroidal components of vector fields are approximated by a single value, evaluated at the aforementioned shifted centroid:
\begin{gather}
  \Psi_{\phi} = \int_{\Omega} R B_{n}^{\phi} \, \diff S \approx S_{\Omega} R (\Omega) B_{n}^{\phi} (\Omega), \label{eq:Psi_phi} \\
  I_{(\phi)} = \int_{\Omega} R J_{n}^{\phi} \, \diff S \approx S_{\Omega} R (\Omega) J_{n}^{\phi} (\Omega). \label{eq:I_phi}
\end{gather}
These degrees of freedom are usually set to a value that assures zero divergence in conjunction with the degrees of freedom of the associated triangle in the poloidal plane.

Some further interpolations will become necessary, using the approximations now established. In the formulae derived in \cref{sec:linmhd}, terms of the form $\vec{v} \cdot \grad \psi$ appear, where $\vec{v}$ is an arbitrary vector, usually the vector of a triangle edge or some field quantity. In the latter case, this reduces to the projection on the normal vector of an edge, since perturbed vector fields are represented by \textsc{Raviart}--\textsc{Thomas} elements. The relation of the degrees of freedom to the contravariant $\psi$ component of the magnetic perturbation on edge \fs\ is derived here as an example, as it is used for computations in \cref{sec:compute_presn,sec:nonres}. The general expression on a given triangle is given by
\begin{gather}
  B_{n}^{\psi} (\Gamma_{\fs}) = \vec{B}_{n} (\Gamma_{\fs}) \cdot \grad \psi (\Gamma_{\fs}) = \vec{B}_{n} (\Gamma_{\fs}) \cdot \hat{\vec{n}}_{\fs} \pd[\psi]{n_{\fs}} (\Gamma_{\fs}).
\end{gather}
Here we used the fact that the gradient of $\psi$ is parallel to $\vec{n}_{\fs}$. To approximate the directional derivative on $\Gamma_{\fs}$, first consider \cref{fig:altitudes}. The indices $\pm 1$ here refer to the adjacent outer and inner flux surface that are realized on grid points. Likewise, $\Omega^{(\pm 1)}$ refers to the triangles that touch the adjacent flux surfaces and edge \fs\ in question. $a_{\fs}$ refers to the altitude of edge \fs\ on a given triangle.
\begin{figure}[bth]
  \centering
  \input{./altitudes.tikz}
  \caption{Geometrical considerations in the calculation of $B_{n}^{\psi} (\Gamma_{\fs})$.}
  \label{fig:altitudes}
\end{figure}
Since $\vec{n}_{\fs}$ is pointing toward the outer flux surface, i.e. it is defined in regard to $\Omega^{(-1)}$, the difference in $\psi$ is computed in the same direction, while the distance between the flux surfaces is approximated by the sum of the altitudes:
\begin{gather}
  \pd[\psi]{n_{\fs}} (\Gamma_{\fs}) \approx \frac{\psi^{(+1)} - \psi^{(-1)}}{a_{\fs}^{(+1)} + a_{\fs}^{(-1)}}.
\end{gather}
The altitudes can be calculated via triangle area and edge length,
\begin{gather}
  S_{\Omega^{(\pm 1)}} = \frac{l_{\fs} a_{\fs}^{(\pm 1)}}{2},
\end{gather}
yielding
\begin{gather}
  \pd[\psi]{n_{\fs}} (\Gamma_{\fs}) \approx \frac{l_{\fs}}{2} \frac{\psi^{(+1)} - \psi^{(-1)}}{S_{\Omega^{(+1)}} + S_{\Omega^{(-1)}}}.
\end{gather}
Now, remembering that $\vec{n}_{\fs} = l_{\fs} \hat{\vec{n}}_{\fs}$ and that the degrees of freedom are given by $\Psi_{\fs} = R (\Gamma_{\fs}) \vec{B}_{n} (\Gamma_{\fs}) \cdot \vec{n}_{\fs}$, we can put everything together and arrive at a direct relation between $B_{n}^{\psi}$ and the degrees of freedom:
\begin{gather}
  B_{n}^{\psi} (\Gamma_{\fs}) \approx \frac{\vec{B}_{n} (\Gamma_{\fs}) \cdot l_{\fs} \hat{\vec{n}}_{\fs}}{2} \frac{\psi^{(+1)} - \psi^{(-1)}}{S_{\Omega^{(+1)}} + S_{\Omega^{(-1)}}} = \frac{\Psi_{\fs}}{2 R} \frac{\psi^{(+1)} - \psi^{(-1)}}{S_{\Omega^{(+1)}} + S_{\Omega^{(-1)}}}. \label{eq:Bnpsi}
\end{gather}
When $\vec{n}_{\fs}$ and $\Psi_{\fs}$ are defined in regard to $\Omega^{(+1)}$ instead, both quantities switch sign. Since $B_{n}^{\psi}$ does not depend on the choice of triangle, \cref{eq:Bnpsi} would gain a minus sign in this case.

Another useful quantity is the covariant $\theta$ component of a vector field, here derived for the example of the current perturbation,
\begin{gather}
  J_{n \theta} = \vec{J}_{n} \cdot \vec{e}_{\theta} = \vec{J}_{n} \cdot \sqrt{g} \left ( \vec{e}^{\rho} \times \vec{e}^{\phi} \right ) = -\vec{J}_{n} \cdot \sqrt{g} (\grad \psi \times \grad \phi) = \vec{J}_{n} \cdot \frac{q \vec{B}_{0}^{\pol}}{B_{0}^{\phi}},
\end{gather}
where we used \cref{eq:flux_metric} in the last step.

\clearpage
\section{Pre-processing of input data}
\label{sec:inputs}

The equilibrium field $\vec{B}_{0}$ is assumed to be available in GEQDSK format, shortly summarized in \cite{Lao97}. It consists of data points given on a rectangular grid which are fitted from measurements to the \textsc{Grad}--\textsc{Shafranov} equation. Parts of NEO-2 code import such a file, generate a field-aligned grid as described in \cref{sec:grid} and supply values of $\vec{B}_{0}$ and its partial derivatives on arbitrary $R, Z$ coordinates by interpolation with splines of fifth order in $R$ and $Z$. In the implementation of NEO-EQ, the necessary values on edge midpoints are cached once before calculations starts as to avoid repeated function calls to spline interpolation.

[\Bvac \ldots]

[grid implementation \ldots]

\subsection{Toroidal unperturbed current}
\label{sec:j0phi}

Since $\vec{B}_{0}$ and $p_{0}$ are directly available as input data, but $\vec{J}_{0}$ is not, the latter will be derived below from \cref{eq:mhd-gen}, the condition of divergence-freeness and symmetry considerations.

We take a cross-product of \cref{eq:mhd-gen} by $\vec{B}_{0}$:
\begin{align}
  \vec{B}_{0} \times \left( \vec{J}_{0} \times \vec{B}_{0} \right) &= B_{0}^{2} \vec{J}_{0} - (\vec{B}_{0} \cdot \vec{J}_{0}) \vec{B}_{0} \nonumber \\
  &= B_{0}^{2} (\vec{J}_{0} - J_{0}^{\parallel} \vec{h}_{0}) \nonumber \\
  &= B_{0}^{2} \vec{J}_{0}^{\perp}.
\end{align}
Therefore
\begin{gather}
  \vec{J}_{0}^{\perp} = \frac{-c \grad p_{0} \times \vec{B}_{0}}{B_{0}^{2}},
\end{gather}
which is the diamagnetic current density. For the parallel current density we use
\begin{align}
 0 = \divg \vec{J}_{0} &= \divg \vec{J}_{0}^{\perp} + \divg (J_{0}^{\parallel} \vec{h}_{0}) \nonumber \\
 &= -c \divg \frac{\grad p_{0} \times \vec{B}_{0}}{B_{0}^{2}} + \vec{B}_{0} \cdot \grad \frac{J_{0}^{\parallel}}{B_{0}}.
\end{align}
In symmetry flux coordinates $(\rho, \phi, \theta)$ and Jacobian $\sqrt{g}$ outlined in \cref{sec:cocos}, the divergence of the diamagnetic current is
\begin{align}
  \divg \vec{J}_{0}^{\perp} &= -\frac{c}{\sqrt{g}} \pd{u^{k}} \left[ \frac{\sqrt{g}}{B_{0}^{2}} \left( \grad p_{0} \times \vec{B}_{0} \right)^{k} \right] \nonumber \\
  &= -\frac{c}{\sqrt{g}} \pd{u^{k}} \left( \frac{\sqrt{g}}{B_{0}^{2}} \frac{\varepsilon^{ijk}}{\sqrt{g}} \pd[p_{0}]{u^{i}} B_{0 j} \right) \nonumber \\
  &= -\frac{c p_{0}' (\rho) B_{0 \phi}}{\sqrt{g}} \pd{\theta} \frac{1}{B_{0}^{2}},
\end{align}
since $p_{0}$ and $B_{0 \phi}$ are constant on a flux surface, $\pd[p_{0}]{\theta} = 0$ and due to axisymmetry $\pd{\zeta} = 0$ for equilibrium quantities. The divergence of the parallel current is
\begin{gather}
  \divg(J_{0}^{\parallel} \vec{h}_{0}) = \vec{B}_{0} \cdot \grad \frac{J_{0}^{\parallel}}{B_{0}} = B_{0}^{\theta} \pd{\theta} \frac{J_{0}^{\parallel}}{B_{0}}.
\end{gather}
With $\sqrt{g} B_{0}^{\theta} = \psi'(\rho) = -1$ as a flux surface quantity, there are no dependencies of $\theta$ in front of the derivatives:
\begin{gather}
  -c p_{0}' (\rho) B_{0 \phi} \pd{\theta} \frac{1}{B_{0}^{2}} + \psi'(\rho) \pd{\theta} \frac{J_{0}^{\parallel}}{B_{0}} = 0.
\end{gather}
Direct integration and a change of variables and notation as in
\begin{gather}
  \frac{p_{0}'(\rho)}{\psi'(\rho)} = \frac{\pd[p_{0}]{\rho}}{\pd[\psi]{\rho}} = \pd[p_{0}]{\psi} = p_{0}'(\psi)
\end{gather}
yields
\begin{gather}
  \frac{-c p_{0}' (\psi) B_{0 \phi}}{B_{0}^{2}} + \frac{J_{0}^{\parallel}}{B_{0}} = C(\psi). \label{eq:j0parallel_general}
\end{gather}
With the extra condition of the flux-surface average\footnote{See \cref{eq:flux_surface_avg}, but note that it is not actually evaluated here.} $\left\langle J_{0}^{\parallel} B_{0} \right\rangle = 0$ for testing without bootstrap current, we obtain
\begin{gather}
  -c p_{0}'(\psi) B_{0 \phi} = C(\psi) \left\langle B_{0}^{2} \right\rangle.
\end{gather}
In general, 
\begin{gather}
  C(\psi) = -\frac{c p_{0}'(\psi) B_{0 \phi}}{\left\langle B_{0}^{2} \right\rangle} D(\psi),
\end{gather}
with $D(\psi)$ set to 1 for now and modified for the more general case $\left\langle J_{0}^{\parallel} B_{0} \right\rangle \not\equiv 0$. Inserting this back into \cref{eq:j0parallel_general} yields
\begin{gather}
  J_{0}^{\parallel} = \frac{c p_{0}'(\psi) B_{0 \phi}}{B_{0}} \left( 1 - \frac{B_{0}^{2}}{\left\langle B_{0}^{2} \right\rangle} D(\psi) \right).
\end{gather}

For the unperturbed toroidal current density we have
\begin{gather}
  J_{0}^{\phi} = J_{0}^{\parallel} h_{0}^{\phi} + \vec{J}_{0}^{\perp} \cdot \grad \phi,
\end{gather}
where
\begin{align}
  J_{0}^{\parallel} h_{0}^{\phi} &= \frac{c p_{0}'(\psi) B_{0 \phi}}{B_{0}} \frac{B_{0}^{\phi}}{B_{0}} \left( 1 - \frac{B_{0}^{2}}{\left\langle B_{0}^{2} \right\rangle} D(\psi) \right) \nonumber \\
  &= c p_{0}'(\psi) \frac{\left( B_{0}^{\tor} \right)^{2}}{B_0^2} \left( 1 - \frac{B_{0}^{2}}{\left\langle B_{0}^{2} \right\rangle} D(\psi) \right) \nonumber \\
  &= c p_{0}'(\psi) \left( B_{0}^{\tor} \right)^{2} \left( \frac{1}{B_{0}^{2}} - \frac{D(\psi)}{\left\langle B_{0}^{2} \right\rangle} \right).
\end{align}
and
\begin{align}
  \vec{J}_{0}^{\perp} \cdot \grad \phi &= \frac{-c p_{0}'(\psi) \grad \phi \cdot (\grad \psi \times \vec{B}_{0})}{B_{0}^{2}} \nonumber \\
  &= \frac{-c p_{0}'(\psi) \vec{B}_{0} \cdot (\grad \phi \times \grad \psi)}{B_{0}^{2}} \\
  &= \frac{c p_{0}'(\psi)}{B_{0}^{2}} \vec{B}_{0}^{\pol} \cdot \vec{B}_{0} \nonumber \\
  &= c p_{0}'(\psi) \frac{\left( B_{0}^{\pol} \right)^{2}}{B_{0}^{2}}.
\end{align}
It follows that
\begin{gather}
  J_{0}^{\phi} = c p_{0}'(\psi) \left( \frac{\left( B_{0}^{\pol} \right)^{2} + \left( B_{0}^{\tor} \right)^{2}}{B_{0}^{2}} - \frac{\left( B_{0}^{\tor} \right)^{2}}{\left\langle B_{0}^{2} \right\rangle} D(\psi)\right) = c p_{0}'(\psi) \left( 1 - \frac{\left( B_{0}^{\tor} \right)^{2}}{\left\langle B_{0}^{2} \right\rangle} D(\psi)\right).
\end{gather}

\subsection{Safety factor}
\label{sec:safety_factor}

Computing the safety factor from \cref{eq:q_field_line_pitch} would require the calculation of $\theta$ coordinate lines from $\vec{B}_{0}$. An equivalent definition from \cite{dHaeseleer91} involves the toroidal flux $\psi_{\tor}$, which in our choice of coordinates is given by
\begin{gather}
  \psi_{\tor} = \frac{1}{(2 \pi)^{2}} \int \diff V \, \vec{B}_{0} \cdot \grad \phi = \frac{1}{2 \pi} \int \diff R \, \diff Z \, R B_{0}^{\phi} = \frac{1}{2 \pi} \int \diff R \, \diff Z \, B_{0 (\phi)}.
\end{gather}
Note that $\psi_{\tor} < 0$ and $\psi_{\tor}' (\rho) < 0$. The safety factor is then given by
\begin{gather}
  q = \frac{\psi_{\tor}' (\rho)}{\psi_{\pol}' (\rho)} = \frac{-\psi_{\tor}' (\psi)}{-\psi_{\pol}' (\psi)} = \td[\psi_{\tor}]{\psi} = \frac{1}{2 \pi} \td{\psi} \int \diff R \, \diff Z \, B_{0 (\phi)}.
\end{gather}
This flux quantity can be evaluated numerically at half-grid steps by adding up $B_{0 (\phi)}$ inside the volume between two flux surfaces and dividing by the the difference in $\psi$:
\begin{gather}
  q \approx \frac{1}{2 \pi \symup{\Delta} \psi} \sum_{k} B_{0 (\phi)} (\Omega^{(k)}) S_{\Omega^{(k)}},
\end{gather}
where the sum is taken over all triangles $\Omega$ inside a triangle strip, and $S_{\Omega}$ is the respective triangle surface area. Note that both $B_{0 (\phi)}$ and $\symup{\Delta} \psi$ are negative, so $q$ is positive overall.

[figure: approximation from test runs]

\clearpage
\section{Linearized MHD force balance}
\label{sec:linmhd}

[\ldots]

\subsection{Pressure perturbation}
\label{sec:compute_presn}

Multiplying \cref{eq:mhd-phi} by $\vec{B}_{0}$ yields
\begin{align}
  c \vec{B}_{0} \cdot \grad p_{n} + \im n c p_{n} \vec{B}_{0} \cdot \grad \phi &= -\vec{B}_{n} \cdot (\vec{J}_{0} \times \vec{B}_{0}) = -c \vec{B}_{n} \cdot \grad p_{0} \nonumber \\
  \vec{B}_{0}^{\pol} \cdot \grad p_{n} + \im n p_{n} B_{0}^{\phi} &= -B_{n}^{\psi} p_{0}'(\psi). \label{eq:pn}
\end{align}
To solve this equation on one flux surface, we use a lowest-order finite difference method. Nodes are indexed by superscript $(k)$ and $\vec{r}^{(k)}$ is the position of node $(k)$, whereas $\vec{l}_{\fs}^{(k)} = \vec{r}^{(k+1)} - \vec{r}^{(k)}$ is the counter-clockwise vector between nodes on edge $\Gamma_{\fs}^{(k)}$. $\grad p_{n}$ is approximated at the midpoint of edge $\Gamma_{\fs}^{(k)}$ as finite difference of $p_{n}$ at nodes $(k)$ and $(k+1)$. $p_{n}$ is accordingly approximated at the midpoint as the arithmetic mean of the values at these nodes. With a shorthand $p_{n}^{(k)} = p_{n} (\vec{r}^{(k)})$ for the degrees of freedom we get
\begin{gather}
  \vec{B}_{0}^{\pol} (\Gamma_{\fs}^{(k)}) \cdot \frac{\vec{l}_{\fs}^{(k)}}{l_{\fs}^{(k)}} \frac{p_{n}^{(k+1)} - p_{n}^{(k)}}{l_{\fs}^{(k)}} + \im n B_{0}^{\phi} (\Gamma_{\fs}^{(k)}) \frac{p_{n}^{(k+1)} + p_{n}^{(k)}}{2} = -\td[p_{0}]{\psi} (\Gamma_{\fs}^{(k)}) B_{n}^{\psi} (\Gamma_{\fs}^{(k)}),
\end{gather}
where a unit vector along the edge is used to get the correct sign for the gradient in the direction of the poloidal magnetic field. Reordering in terms of the unknowns yields
\begin{gather}
  (b_{k} + a_{k}) p_{n}^{(k+1)} + (b_{k} - a_{k}) p_{n}^{(k)} = s_{k}
\end{gather}
with
\begin{align}
  a_{k} &= \vec{B}_{0}^{\pol} (\Gamma_{\fs}^{(k)}) \cdot \frac{\hat{\vec{l}}_{\fs}^{(k)}}{l_{\fs}^{(k)}}, \\
  b_{k} &= \frac{\im n B_{0}^{\phi} (\Gamma_{\fs}^{(k)})}{2}, \\
  s_{k} &= -\td[p_{0}]{\psi} (\Gamma_{\fs}^{(k)}) B_{n}^{\psi} (\Gamma_{\fs}^{(k)}).
\end{align}
In matrix form this scheme is written as
\begin{gather}
  K_{jk} p_{n}^{(k)} = s_{j},
\end{gather}
where the elements of the matrix $\hat{K}$ are
\begin{gather}
  K_{jk} = (b_{j} + a_{j}) \delta_{j-1, k} + (b_{j} - a_{j}) \delta_{jk}.
\end{gather}
Note that for $N$ nodes with periodic boundary conditions $p_{n}^{(0)} = p_{n}^{(N)}$, indices "wrap around", resulting in the following shape for the stiffness matrix:
\begin{gather*}
  \hat{K} = \begin{pmatrix}
    b_{1} - a_{1} &  b_{1} + a_{1} &        0       & \hdots &    0   \\
           0       & b_{2} - a_{2} &  b_{2} + a_{2} & \hdots &    0   \\
           0       &        0       & b_{3} - a_{3} & \hdots &    0   \\
        \vdots     &     \vdots     &     \vdots     & \ddots & \vdots \\
     b_{N} + a_{N} &        0       &        0       & \hdots & b_{N} - a_{N}
  \end{pmatrix}.
\end{gather*}

\subsection{Current perturbation}
\label{sec:compute_currn}

To derive an expression for the degrees of freedom of $\vec{J}_{n}$, we start from the linear force balance in \cref{eq:mhd-phi} and put the unknown current perturbation on one side:
\begin{gather}
  \underbrace{\vec{J}_{n} \times \vec{B}_{0}}_{\text{(I)}} = \underbrace{c (\grad p_{n} + \im n p_{n} \grad \phi)}_{\text{(II)}} - \underbrace{\vec{J}_{0} \times \vec{B}_{n}}_{\text{(III)}}. \label{eq:jnxB0}
\end{gather}
Taking a scalar product of some edge $\vec{l}$ -- in the course of this derivation, we don't indicate evaluation at the edge midpoint $\Gamma$ to avoid cluttering up the equations -- with term (I) in \cref{eq:jnxB0} yields
\begin{align}
  \vec{l} \cdot (\vec{J}_{n} \times \vec{B}_{0}) &= \vec{l} \cdot (\vec{J}_{n} \times (\grad \psi \times \grad \phi + B_{0 \phi} \grad \phi)) \\
  \intertext{with the definiton of the equilibrium field from \cref{eq:B_pol_tor}. Cyclic permutation gives}
  \vec{l} \cdot (\vec{J}_{n} \times \vec{B}_{0}) &= \vec{J}_{n} \cdot ((\grad \psi \times \grad \phi) \times \vec{l} + B_{0 \phi} \grad \phi \times \vec{l}), \\
  \intertext{where another triple product formula and the definition of the local coordinates from \cref{eq:edge_n} can be applied:}
  \vec{l} \cdot (\vec{J}_{n} \times \vec{B}_{0}) &= \vec{J}_{n} \cdot \left ( (\vec{l} \cdot \grad \psi) \grad \phi + \frac{B_{0 \phi}}{R} \vec{n} \right ). \\
  \intertext{Changing from co- to contravariant coordinates and carrying out the scalar product yields}
  \vec{l} \cdot (\vec{J}_{n} \times \vec{B}_{0}) &= (\vec{l} \cdot \grad \psi) J_{n}^{\phi} + R B_{0}^{\phi} \vec{J}_{n}^{\pol} \cdot \vec{n}.
\end{align}
On the right-hand side, we can insert the definition from \cref{eq:edge_l}, reorder and in the result replace the definition from \cref{eq:B_pol}, giving
\begin{gather}
  \vec{l} \cdot \grad \psi = \left( \vec{n} \times R \grad \phi \right) \cdot \grad \psi = -R \vec{B}_{0}^{\pol} \cdot \vec{n}. \label{eq:l_grad_psi}
\end{gather}
Finally,
\begin{gather}
  \vec{l} \cdot (\vec{J}_{n} \times \vec{B}_{0}) = R B_{0}^{\phi} \vec{J}_{n}^{\pol} \cdot \vec{n} - R J_{n}^{\phi} \vec{B}_{0}^{\pol} \cdot \vec{n}. \label{eq:jnxB0_I}
\end{gather}
Multiplying term (II) of \cref{eq:jnxB0} by $\vec{l}$ simply gives
\begin{gather}
  \vec{l} \cdot (\grad p_{n} + \im n p_{n} \grad \phi) = \vec{l} \cdot \grad p_{n}. \label{eq:jnxB0_II}
\end{gather}
We repeat the same procedure for term (III) of \cref{eq:jnxB0} and expand the cross product by poloidal-toroidal decomposition:
\begin{gather}
  \vec{l} \cdot (\vec{J}_{0} \times \vec{B}_{n}) = \vec{l} \cdot (B_{n \phi} \vec{J}_{0}^{\pol} \times \grad \phi + J_{0 \phi} \grad \phi \times \vec{B}_{n}^{\pol}).
\end{gather}
For the second term in parentheses, we again use cyclic permutation and the definition from \cref{eq:edge_n}:
\begin{align}
  \vec{l} \cdot (\grad \phi \times \vec{B}_{n}^{\pol}) &= \vec{B}_{n}^{\pol} \cdot (\vec{l} \times \grad \phi) \nonumber \\
  &= -\frac{1}{R} \vec{B}_{n}^{\pol} \cdot \vec{n}.
\end{align}
To simplify the first term in parentheses, we start from the equilibrium in \cref{eq:mhd-gen} and apply some of the previously used identities:
\begin{align}
  c \grad p_{0} &= \vec{J}_{0} \times \vec{B}_{0} \nonumber \\
  &= \vec{J}_{0}^{\pol} \times (B_{0 \phi} \grad \phi) + J_{0 \phi} \grad \phi \times (\grad \psi \times \grad \phi) \nonumber \\
  &= \vec{J}_{0}^{\pol} \times (B_{0 \phi} \grad \phi) + \frac{J_{0 \phi}}{R^{2}} \grad \psi \nonumber \\
  &= \vec{J}_{0}^{\pol} \times (B_{0 \phi} \grad \phi) + J_{0}^{\phi} \grad \psi.
\end{align}
Rearrangement yields
\begin{gather}
  \vec{J}_{0}^{\pol} \times \grad \phi = \frac{1}{B_{0 \phi}} \left( c \grad p_{0} - J_{0}^{\phi} \grad \psi \right).
\end{gather}
The intermediate result is
\begin{gather}
  \vec{l} \cdot (\vec{J}_{0} \times \vec{B}_{n}) = \frac{B_{n \phi}}{B_{0 \phi}} \left ( c \grad p_{0} - J_{0}^{\phi} \grad \psi \right ) \cdot \vec{l} - \frac{J_{0 \phi}}{R} \vec{B}_{n}^{\pol} \cdot \vec{n}.
\end{gather}
Reusing \cref{eq:l_grad_psi} and rearranging, we get
\begin{gather}
  \vec{l} \cdot (\vec{J}_{0} \times \vec{B}_{n}) = \frac{B_{n \phi}}{B_{0 \phi}} c \grad p_{0} \cdot \vec{l} + R J_{0}^{\phi} \left ( \frac{B_{n \phi}}{B_{0 \phi}} \vec{B}_{0}^{\pol} \cdot \vec{n} - \vec{B}_{n}^{\pol} \cdot \vec{n} \right ). \label{eq:jnxB0_III}
\end{gather}
Combining \cref{eq:jnxB0_I,eq:jnxB0_II,eq:jnxB0_III}, \cref{eq:jnxB0} is transformed to \cref{eq:jnphi-jnpol}:
\begin{gather}
  R B_{0}^{\phi} \vec{J}_{n}^{\pol} \cdot \vec{n} - R J_{n}^{\phi} \vec{B}_{0}^{\pol} \cdot \vec{n} = c \left ( \grad p_{n} - \frac{B_{n \phi}}{B_{0 \phi}} \grad p_{0} \right ) \cdot \vec{l} - R J_{0}^{\phi} \left ( \frac{B_{n \phi}}{B_{0 \phi}} \vec{B}_{0}^{\pol} \cdot \vec{n} - \vec{B}_{n}^{\pol} \cdot \vec{n} \right ). \label{eq:jnphi-jnpol}
\end{gather}
On edges \inw\ and \out\ where $\vec{B}_{0}^{\pol} \cdot \vec{n} \neq 0$, we can divide by this term and we obtain an expression for $J_{n}^{\phi}$ in terms of $\vec{J}_{n}^{\pol} \cdot \vec{n}$ and quantities which are known at this point:
\begin{gather}
  R J_{n}^{\phi} = J_{n (\phi)} = R B_{0}^{\phi} \frac{\vec{J}_{n}^{\pol} \cdot \vec{n}}{\vec{B}_{0}^{\pol} \cdot \vec{n}} + \frac{c}{\vec{B}_{0}^{\pol} \cdot \vec{n}} \left ( \frac{B_{n \phi}}{B_{0 \phi}} \grad p_{0} - \grad p_{n} \right ) \cdot \vec{l} + R J_{0}^{\phi} \left ( \frac{B_{n \phi}}{B_{0 \phi}} - \frac{\vec{B}_{n}^{\pol} \cdot \vec{n}}{\vec{B}_{0}^{\pol} \cdot \vec{n}} \right ). \label{eq:jnphi}
\end{gather}
On edge \fs, $\vec{B}_{0}^{\pol} \cdot \vec{n} = 0$ and $\grad p_{0} \cdot \vec{l} = 0$ (compare \cref{eq:l_grad_psi}), thus from \cref{eq:jnphi-jnpol}, no connection between $J_{n}^{\phi}$ and $\vec{J}_{n}^{\pol} \cdot \vec{n}$ can be made, but the latter expression can be given in terms of already knwown quantities:
\begin{gather}
  R \vec{J}_{n}^{\pol} \cdot \vec{n} = \frac{c \grad p_{n} \cdot \vec{l}}{B_{0}^{\phi}} + R \frac{J_{0}^{\phi}}{B_{0}^{\phi}} \vec{B}_{n}^{\pol} \cdot \vec{n}. \label{eq:If}
\end{gather}
With these relations established, we now consider the divergence of the perturbation current from \cref{eq:divfree-phi}. In cylindrical coordinates it reads, after multiplication by $R$,
\begin{gather}
  \pd{R} (R J_{n}^{k}) + \im n R J_{n}^{\phi} + \pd{Z} (R J_{n}^{k}) = 0.
\end{gather}
Using the divergence theorem this can also be written in integral form in a specific triangular mesh element $\Omega^{(k)}$ as
\begin{gather}
  \oint_{\partial \Omega^{(k)}} R \vec{J}_{n}^{\pol} \cdot \hat{\vec{n}} \, \diff l + \im n \int_{\Omega^{(k)}} R J_{n}^{\phi} \, \diff R \, \diff Z = 0.
\end{gather}
Here the first integral is performed over the 1-dimensional element boundary $\partial \Omega^{(k)} = \Gamma^{(k)}$. The first term is split into three contributions,
\begin{gather}
  \oint_{\partial \Omega^{(k)}} R \vec{J}_{n}^{\pol} \cdot \hat{\vec{n}} \, \diff l = \int_{\Gamma_{\inw}^{(k)}, \Gamma_{\out}^{(k)}} R \vec{J}_{n}^{\pol} \cdot \hat{\vec{n}} \, \diff l + \int_{\Gamma_{\fs}^{(k)}} R \vec{J}_{n}^{\pol} \cdot \hat{\vec{n}} \, \diff lx,
\end{gather}
where edge \fs\ is tangential to an adjacent flux surface and edges \inw\ and \out\ are not. Using the notation for currents established in \cref{eq:I_k}, we have
\begin{gather}
  I_{\inw} + I_{\out} + \im n \int_{\Omega} R J_{n}^{\phi} \diff S = -I_{\fs}.
\end{gather}
 $I_{\fs}$ is already known from \cref{eq:If} and therefore acts as a source on the right-hand side. The remaining currents $I_{\inw}$ and $I_{\out}$ are taken as unknowns. Since the current $I_{\out}$ flowing out of one triangle is equalto the current $-I_{\inw}$ flowing into the next triangle, these unknowns are connected on one strip of triangles and we expect a system of equations similar to the one in \cref{sec:compute_presn}. The degrees of freedom and the unknowns are illustrated in \cref{fig:current_perturbation} with the unknowns marked in red, along with the indexing described further below. 
\begin{figure}[bth]
  \centering
  \input{./current_perturbation.tikz}
  \caption{Schematic of the degrees of freedom and unknowns in the calculation of currents.}
  \label{fig:current_perturbation}
\end{figure}

Now, we deviate from \cref{eq:I_phi} and use a different approximation for the remaining integral:
\begin{gather}
  \im n I_{\phi} = \im n \int_{\Omega} R J_{n}^{\phi} \, \diff S \approx \im n S_{\Omega} \frac{R (\Gamma_{\inw}) J_{n}^{\phi} (\Gamma_{\inw}) + R (\Gamma_{\out}) J_{n}^{\phi} (\Gamma_{\out})}{2}.
\end{gather}
In this approximation, a term $R (\Gamma_{\fs}) J_{n}^{\phi} (\Gamma_{\fs})$ is neglected because within one strip of triangles, edge \fs\ alternates between the inner and outer flux surface and this \enquote{oscillation} of sample points would carry over to the approximation values, which is similar to the argument regarding the shifted centroid in \cref{sec:dofs}. Furthermore, $J_{n}^{\phi} (\Gamma_{\fs}) \cdot \vec{n}$ can't be reformulated in terms of $\vec{J}_{n}^{\pol} (\Gamma_{\fs})$ via \cref{eq:jnphi}, which would introduce the former as another unknown and lead to an overdetermined set of equations, possibly violating divergence-freeness. So instead, $I_{\phi}$ on each triangle is given by
\begin{gather}
  \im n I_{\phi} = \im n \int_{\Omega} R J_{n}^{\phi} \, \diff S \approx \frac{\im n S_{\Omega}}{2} \left ( \frac{B_{0}^{\phi} (\Gamma_{\inw})}{\vec{B}_{0}^{\pol} (\Gamma_{\inw}) \cdot \vec{n}_{\inw}} I_{\inw} + \frac{B_{0}^{\phi} (\Gamma_{\out})}{\vec{B}_{0}^{\pol} (\Gamma_{\out}) \cdot \vec{n}_{\out}} I_{\out} + \dotsb \right ),
\end{gather}
where we effectively reduced $I_{\phi}$ to $I_{\inw}$, $I_{\out}$ and already known terms by the relation between $\vec{J}_{n}^{\pol} \cdot \vec{n}$ and $J_{n}^{\phi}$ in \cref{eq:jnphi}. The remaining terms are moved to the right-hand-side as sources $s$, so the discretized equation in each triangle $\Omega$ is
\begin{gather}
  \left ( 1 + \frac{\im n S_{\Omega}}{2} \frac{B_{0}^{\phi} (\Gamma_{\inw})}{\vec{B}_{0}^{\pol} (\Gamma_{\inw}) \cdot \vec{n}_{\inw}} \right ) I_{\inw} + \left ( 1 + \frac{\im n S_{\Omega}}{2} \frac{B_{0}^{\phi} (\Gamma_{\out})}{\vec{B}_{0}^{\pol} (\Gamma_{\out}) \cdot \vec{n}_{\out}} \right ) I_{\out} = s. \label{eq:Ii-Io}
\end{gather}
The source term is given by
\begin{gather}
  s = -I_{\fs} - \frac{\im n S_{\Omega}}{2} \sum_{k = \inw, \out} \frac{c}{\vec{B}_{0}^{\pol} \cdot \vec{n}_{k}} \left ( \frac{B_{n \phi}}{B_{0 \phi}} \grad p_{0} - \grad p_{n} \right ) \cdot \vec{l}_{k} + R J_{0}^{\phi} \left ( \frac{B_{n \phi}}{B_{0 \phi}} - \frac{\vec{B}_{n}^{\pol} \cdot \vec{n}_{k}}{\vec{B}_{0}^{\pol} \cdot \vec{n}_{k}} \right ),
\end{gather}
where we again ommited evaluation at $\Gamma_{k}$ for the sake of brevity. Note that $\vec{B}_{n} (\Gamma_{k}) \cdot \vec{n}_{k}$ can be directly retrieved from $\Psi_{k}$, while $B_{n \phi} (\Gamma_{k})$ has to be calculated by averaging adjacent $B_{n \phi} (\Omega)$. The directional derivatives $\vec{l}_{k} \cdot \grad p_{n} (\Gamma_{k})$ are approximated by a difference quotient with values taken at the nodes (for indexing see \cref{fig:grid}),
\begin{align}
  \vec{l}_{\inw} \cdot \grad p_{n} (\Gamma_{\inw}) = l_{\inw} \hat{\vec{l}}_{\inw} \cdot \grad p_{n} (\Gamma_{\inw}) = l_{\inw} \pd[p_{n}]{\vec{l}_{\inw}} (\Gamma_{\inw}) & \approx l_{\inw} \frac{p_{n} (\vec{r}_{\vout}) - p_{n} (\vec{r}_{\vfs})}{\norm{\vec{r}_{\vout} - \vec{r}_{\vfs}}} = p_{n} (\vec{r}_{\vout}) - p_{n} (\vec{r}_{\vfs}), \\
  \vec{l}_{\out} \cdot \grad p_{n} (\Gamma_{\out}) = l_{\out} \hat{\vec{l}}_{\out} \cdot \grad p_{n} (\Gamma_{\out}) = l_{\out} \pd[p_{n}]{\vec{l}_{\out}} (\Gamma_{\out}) & \approx l_{\out} \frac{p_{n} (\vec{r}_{\vfs}) - p_{n} (\vec{r}_{\vinw})}{\norm{\vec{r}_{\vfs} - \vec{r}_{\vinw}}} = p_{n} (\vec{r}_{\vfs}) - p_{n} (\vec{r}_{\vinw}),
\end{align}
where the sign has to be reversed for the type of triangle with node \vfs\ on the outer flux surface. This is actually a shortcoming of the convention that nodes are named according to their opposite edges; in the implementation, we use a subroutine that gives the nodes of edges in consistent counter-clockwise order, so this case distinction is not necessary at this level. The same logic applies to $\vec{l} \cdot \grad p_{0}$ terms.

For the global\footnote{in this case only referring to the current triangle strip, as opposed to the local indexing of individual triangles} indexing scheme, we call the ingoing current into triangle $(k)$ counted in clockwise direction $I^{(k)}$. In triangle $(k)$, this is equal to $I_{\inw} = -I^{(k)}$ and $I_{\out} = I^{(k+1)}$. This is also illustrated in \cref{fig:current_perturbation}, where triangles are counted from one starting at the right end of the sketch. The matrix form of \cref{eq:Ii-Io} is then
\begin{gather}
  K_{jk} I^{(k)} = s_{j},
\end{gather}
where the elements of the stiffness matrix $\hat{K}$ are
\begin{gather}
  K_{jk} = -\left ( 1 + \frac{\im n S_{\Omega^{(j)}}}{2} \frac{B_{0}^{\phi} (\Gamma_{\inw}^{(j)})}{\vec{B}_{0}^{\pol} (\Gamma_{\inw}^{(j)}) \cdot \vec{n}_{\inw}^{(j)}} \right) \delta_{jk} + \left( 1 + \frac{\im n S_{\Omega^{(j)}}}{2} \frac{B_{0}^{\phi} (\Gamma_{\out}^{(j)})}{\vec{B}_{0}^{\pol} (\Gamma_{\out}^{(j)}) \cdot \vec{n}_{\out}^{(j)}} \right) \delta_{j+1, k}.
\end{gather}

\clearpage
\section{Magnetic field perturbation}
\label{sec:compute_Bn}

[\ldots]

The weak form used in \texttt{FreeFEM++} is given by  % rework!
\begin{gather}
  \int_{\Omega} \left ( \polCurl \vec{w} R \polCurl \vec{a} + \frac{1}{R} n^{2} w_{k} a_{k} \right ) \, \diff \Omega + \frac{4 \pi}{c} \int_{\Omega} w_{k} j_{k} = 0.
\end{gather}

[For details see \cite{Albert19,Biro15,Hecht12,Jin02}.]

\clearpage
\section{Construction of test cases and analysis of results}

Along with comparison to results from NEO-2, special test cases altering different components of the calculation are considered. In \cref{sec:nonres}, $\Bvac$ is not taken from \textsc{Biot}--\textsc{Savart} calculations of currents in external coils as per \cref{eq:biot-savart,sec:inputs}, but constructed directly to avoid resonances, at least in the first iteration step. \Cref{sec:analytical} instead looks at the analytical solution in the cylindrical limit on a circular cross-section obtained from KilCa, effectively changing the grid geometry.

\subsection{Generating a non-resonant test field}
\label{sec:nonres}

The axisymmetric equilibrium field $\vec{B}_{0}$ lies on nested flux surfaces $\psi = \text{const.}$, meaning
\begin{gather*}
  \vec{B}_{0} \cdot \grad \psi = B_{0}^{\psi} = 0.
\end{gather*}
If the perturbed field shall still lie on distorted, but not broken, flux surfaces (non-resonant, without magnetic islands), a new flux surface label $\psi + \delta \psi$ must exist fulfilling
\begin{gather*}
  (\vec{B}_{0} + \Bpert) \cdot \grad (\psi + \delta \psi) = 0
\end{gather*}
for the perturbed magnetic field $\vec{B}_{0} + \Bpert$, where $\delta \psi$ remains small and continuous within the plasma. In that case we can use a linear order expansion
\begin{gather}
  \underbrace{\vec{B}_{0} \cdot \grad \psi}_{= 0} + \vec{B}_{0} \cdot \grad \delta \psi + \Bpert \cdot \grad \psi + \mathcal{O}(\delta^{2}) = 0,
\end{gather}
or in coordinate form with symmetry flux coordinates $(\rho, \phi, \theta)$ outlined in \cref{sec:cocos},
\begin{gather}
  B_{0}^{\theta} \pd{\theta} \delta \psi + B_{0}^{\phi} \pd{\phi} \delta \psi + \delta B^{\rho} \psi' (\rho) = 0.
\end{gather}
Here we have used $\grad \psi = \psi' (\rho) \grad \rho$. Further, $\psi' (\rho) = -1$. With safety factor
\begin{gather*}
  q = \frac{B_{0}^{\phi}}{B_{0}^{\theta}}
\end{gather*}
and dividing by $B_{0}^{\theta}$, we obtain
\begin{gather}
  \left ( \pd{\theta} + q \pd{\phi} \right ) \delta \psi = \frac{\delta B^{\rho}}{B_{0}^{\theta}} = -\sqrt{g} \delta B^{\rho} = \sqrt{g} \delta B^{\psi}.
\end{gather}
Written in terms of toroidal Fourier harmonics $m, n$ in $\theta, \phi$ the equation becomes
\begin{gather*}
  \psi_{m n} = \frac{\left ( \sqrt{g} \delta B^{\psi} \right )_{m n}}{m + n q} = \frac{\left ( \sqrt{g} B_{n}^{\psi} \right )_{m}}{m + n q}.
\end{gather*}
$\sqrt{g}$ depends also on $\theta$, so poloidal harmonics $m$ have to be taken outside the bracket here. In order to fulfill the original requirement not to break flux surfaces, $\psi_{m n}$ must never diverge, so $m + n q$ must not become zero. We can avoid such resonant surfaces if
\begin{gather}
  \left ( \sqrt{g} B_{n}^{\psi} \right )_{m} \overset{!}{=} 0
\end{gather}
for all possible $m$ that could lead to a resonance. The simplest way to do so is to make $\sqrt{g} B_{n}^{\psi}$ a flux function, possessing only the poloidally symmetric harmonic $m = 0$. More generally, also $-m < n q_{\text{min}}$ and $-m > n q_{\text{max}}$ are possible, but for nonzero $m$ a transformation to the flux angle $\theta$ has to be computed explicitly.

Using the Jacobian of symmetry flux coordinates from \cref{eq:flux_metric}, we obtain
\begin{gather}
  \psi_{m n} = \frac{q}{m + n q} \left( \frac{R^{2}}{B_{0 \phi}} B_{n}^{\psi} \right)_{m}
\end{gather}
and so, to generate a non-resonant field, we are allowed to use any value
\begin{gather}
  B_{n}^{\psi} = C(\psi) \frac{B_{0 \phi}}{R^{2}}, \label{eq:Bnpsi_vac}
\end{gather}
where $C(\psi)$ is a flux function. The other components of $\Bpert$ are not relevant for the resonance condition and just need to fulfill divergence-freeness. Thus we proceed as in \cref{sec:compute_currn} and find fluxes through triangle edges:
\begin{gather}
  \int_{\Gamma_{\inw}, \Gamma_{\out}} R \vec{B}_{n}^{\pol} \cdot \vec{n} \, \diff l = -\int_{\Gamma_{\fs}} R \vec{B}_{n}^{\pol} \cdot \vec{n} \, \diff l - \im n \int_{\Omega} R B_{n}^{\phi} \, \diff R \, \diff Z. \label{eq:Bn_divfree}
\end{gather}
As for currents we use the notation $\Psi_{k}$ for weighted magnetic fluxes through edges as in \cref{eq:Psi_k},
\begin{gather}
  \Psi_{k} = \int_{\Gamma_{k}} R \vec{B}_{n}^{\pol} \cdot \vec{n} \, \diff l \approx R (\Gamma_{k}) \vec{B}_{n}^{\pol} (\Gamma_{k}) \cdot \vec{n}_{k},
\end{gather}
and, differing from the procedure in \cref{sec:compute_currn}, the same for the weighted toroidal magnetic flux $\Psi_{\phi}$ as per \cref{eq:Psi_phi},
\begin{gather}
  \Psi_{\phi} = \int_{\Omega} R B_{n}^{\phi} \, \diff R \, \diff Z \approx S_{\Omega} \, R (\Omega) B_{n}^{\phi} (\Omega),
\end{gather}
resulting in a shortened notation for \cref{eq:Bn_divfree} where the system of equations to be assembled is more apparent:
\begin{gather}
  \Psi_{\inw} + \Psi_{\out} = -\Psi_{\fs} - \im n \Psi_{\phi}.
\end{gather}
Again, the flux through edge \fs\ is fixed, so we rearrange \cref{eq:Bnpsi} and get
\begin{gather}
  \Psi_{\fs} \approx 2 R (\Gamma_{\fs}) B_{n}^{\psi} (\Gamma_{\fs}) \frac{S_{\Omega^{(+1)}} + S_{\Omega^{(-1)}}}{\psi^{(+1)} - \psi^{(-1)}}, \label{eq:Psi_f}
\end{gather}
where $B_{n}^{\psi}$ is given by \cref{eq:Bnpsi_vac}.

The system of linear equations to solve is
\begin{gather}
  K_{jk} \Psi^{(k)} = s_{j} \quad \forall j, k = 1, 2, \dotsc, N,
\end{gather}
with
\begin{gather}
  K_{jk} = \delta_{j-1, k} - \delta_{jk} \rightarrow \hat{K} = \begin{pmatrix}
    -1   &    1   &    0   & \hdots &    0   \\
     0   &   -1   &    1   & \hdots &    0   \\
     0   &    0   &   -1   & \hdots &    0   \\
  \vdots & \vdots & \vdots & \ddots & \vdots \\
     1   &    0   &    0   & \hdots &   -1
  \end{pmatrix}
\end{gather}
and
\begin{gather}
  s_{j} = -\Psi_{\fs}^{(j)} - \im n \Psi_{\phi}^{(j)}.
\end{gather}
Since any one column in $\hat{K}$ is a linear combination of all other columns, $\hat{K}$ is of rank $N - 1$ and thus singular. To construct a solution, we first consider the homogenous case with $\vec{s} = \vec{0}$, which also determines the toroidal flux. The non-zero solution for the remaining degrees of freedom then assumes the simple form
\begin{gather}
  \Psi^{(k)} = C_{0} \quad \forall k = 1, 2, \dotsc, N,
\end{gather}
with an arbitrary constant $C_{0}$. With local indices, the degrees of freedom are written as 
\begin{align}
  \Psi_{\inw}^{(k)} &= -C_{0}, & \Psi_{\out}^{(k)} &= C_{0} & \Psi_{\phi}^{(k)} &= \frac{\im}{n} \Psi_{\fs}^{(k)} \quad \forall k = 1, 2, \dotsc, N. \label{eq:Psi_hom}
\end{align}
This means that flux conservation, i.e.\ divergence-freeness, is fulfilled by balancing $\Psi_{\phi}$ with $\Psi_{\fs}$ on each individual triangle and assigning a constant flux $C_{0}$ in poloidal direction to $\Psi_{\inw}$ and $\Psi_{\out}$ over the entire triangle strip.

A consistent solution according to the \textsc{Rouché}-\textsc{Capelli} theorem can also be constructed for the inhomogeneous case, i.e.\ non-zero $\vec{s}$, as long as $\vec{s}$ is a linear combination of columns of $K$. Starting from the trivial (zero) solution to the homogeneous case and for a fixed $k$, we add to $\vec{s}$ the $(k+1)$-th column of $\hat{K}$, multiplied by another arbitrary constant $C_{k}$, resulting in
\begin{align}
  s_{k} &= -\Psi_{\fs}^{(k)} - \im n \Psi_{\phi}^{(k)} = C_{k}, \\
  s_{k+1} &= -\Psi_{\fs}^{(k+1)} - \im n \Psi_{\phi}^{(k+1)} = -C_{k}.
\end{align}
Considering the two equations affected compared to the homogeneous case,
\begin{align}
  -\Psi^{(k-1)} + \Psi^{(k)} &= C_{k}, \\
  -\Psi^{(k)} + \Psi^{(k+1)} &= -C_{k},
\end{align}
we arrive at a particular solution
\begin{gather}
  \Psi^{(k)} = C_{k}, \quad \Psi^{(j)} = 0 \quad \forall j \neq k.
\end{gather}
The degrees of freedom differing from the solution to the zero solution (\cref{eq:Psi_hom} with $C_{0} = 0$) are, given with local indices:
\begin{align}
  \Psi_{\inw}^{(k)} &= 0, & \Psi_{\out}^{(k)} &= C_{k}, & \Psi_{\phi}^{(k)} &= \frac{\im}{n} \Psi_{\fs}^{(k)} - \frac{\im}{n} C_{k}, \\
  \Psi_{\inw}^{(k+1)} &= -C_{k}, & \Psi_{\out}^{(k+1)} &= 0, & \Psi_{\phi}^{(k+1)} &= \frac{\im}{n} \Psi_{\fs}^{(k+1)} + \frac{\im}{n} C_{k}.
\end{align}
This means that, compared to the zero solution, a change $C_{k}$ in the flux across the associated edge of adjacent triangles in one triangle strip is accomdated by a change in the toroidal flux of these triangles.

The approach outlined above can be repeated for different values of $k$. Linear superposition of the solutions to the homogeneous and inhomogeneous cases then yields the most general solution,
\begin{align}
  \Psi_{\inw}^{(k)} &= -C_{0} - C_{k-1}, & \Psi_{\out}^{(k)} &= C_{0} + C_{k}, & \Psi_{\phi}^{(k)} &= \frac{\im}{n} \Psi_{\fs}^{(k)} + \frac{\im}{n} C_{k-1} - \frac{\im}{n} C_{k} \quad \forall k = 1, 2, \dotsc, N.
\end{align}
Now, to assign sensible values to the arbitrary constants, consider the solution to the homogeneous sytem of equations. Since edge \fs\ alternates between inner and outer flux surface for all but the innermost triangle strip, $\vec{n}_{\fs}$ will also alternate between pointing inwards and outwards. Thus $\Psi_{\fs}$ will alternate signs too, but it is consistent along one flux surface. Since $\Psi_{\phi}$ depends linearly on $\Psi_{\fs}$, on any one triangle the sign of $B_{n (\phi)}$ will differ from all three adjacent triangles, except for the innermost triangle strip. The resulting field is then clearly dependent on the choice of the grid. The procedure described before can be used to alleviate this problem. On every pair of triangles $\Omega^{(2k)}$ and $\Omega^{(2k+1)}$ -- which originally result from diagonally dividing a more regular quadrilateral -- we average $\Psi_{\phi}$ and set $C_{2k}$ to the deviation to counterbalance the change:
\begin{align}
  C_{2k} &= \frac{\im}{2 n} \left( \Psi_{\fs}^{(2k)} - \Psi_{\fs}^{(2k+1)} \right) \quad \forall k = 0, 1, \dotsc, \frac{N}{2} - 1.
\end{align}

\subsection{Analytical solution for very large aspect ratios}
\label{sec:analytical}

Using flux coordinates $(r, \theta, \phi)$, a term in \cref{eq:pn} can be simplified:
\begin{gather}
  \vec{B}_{0}^{\pol} \cdot \grad p_{n} = B_{0}^{\theta} \vec{e}_{\theta} \cdot \grad p_{n} = B_{0}^{\theta} \pd[p_{n}]{\theta}.
\end{gather}
Now when we expand the perturbed quantities as series in $\theta$ as well as $\phi$ so that
\begin{gather}
  \delta p = \sum_{n} p_n(r, \theta) \e^{\im n \phi} = \sum_{m, n} p_{mn}(r) \e^{\im m \theta + \im n \phi},
\end{gather}
\cref{eq:pn} reduces to
\begin{gather}
  \im m p_{mn} B_{0}^{\theta} + \im n p_{mn} B_{0}^{\phi} = -B_{mn}^{r} p_{0}'(r) =: -s_{mn}
\end{gather}
with a source term $s_{mn}$. This allows a simple algebraic solution where all quantities depend only on $r$:
\begin{gather}
  p_{mn} =  \frac{\im s_{mn}}{m B_{0}^{\theta} + n B_{0}^{\phi}}.
\end{gather}
Now an approximation can be made by switching from contravariant components to covariant components which are (for some reason) assumed to be constant. The factor $R$ appearing in the metric components can also be considered constant over the domain in question -- the toroidal geometry is effectively transformed to cylindrical geometry with a very thin and elongated cylinder and periodic boundary conditions.

[\ldots]

\clearpage
\appendix
\section{List of symbols}

\begin{longtable}{l >{\RaggedRight}p{0.8\textwidth}}
  \caption{Base symbols} \\
  \toprule
  \textbf{Notation} & \textbf{Description} \\
  \midrule
  \endhead
  \label{tab:symbols}%
  $\vec{B}$ & magnetic field strength, measured in Gauss \\
  $\Bplas$ & perturbation field from \emph{p}lasma current \\
  $\Bvac$ & perturbation field in \emph{v}acuum (from external coils) \\
  $C$ & arbitrary constant (of integration) \\
  $c$ & speed of light in centimetres per second \\
  $\e$ & \textsc{Euler}'s constant, base of natural logarithm \\
  $g$ & metric determinant \\
  $\vec{h}_{0}$ & unit vector of $\vec{B}_{0}$ \\
  $\hat{I}$ & unit matrix \\
  $I$ & electric current \\
  $I_{\text{c}}$ & electric current produced by RMP \emph{c}oils \\
  $\im$ & imaginary unit, $\im^{2} = -1$ \\
  $\vec{J}$ & electric current density, measured in statampere \\
  $\hat{K}$ & combined linear operator $\hat{M} \hat{P}$ / stiffness matrix \\
  $\vec{l}$ & edge vector in counter-clockwise direction \\
  $l$ & length of edge \\
  $\hat{M}$ & linear operator representing computation of the magnetic field from the currents via \textsc{Ampère}'s equation \\
  $m$ & poloidal mode number \\
  $n$ & toroidal mode number \\
  $\vec{n}$ & outward pointing normal vector \\
  $N$ & dimension of system of linear equations \\
  $\hat{P}$ & linear operator representing computation of the currents from the magnetic field via MHD equations \\
  $p$ & pressure, measured in dyne per square centimetre \\
  $q$ & safety factor \\
  $R$ & radial coordinate in cylindrical coordinates \\
  $R_{0}$ & major radius of the tokamak \\
  $S$ & area in poloidal cross-section \\
  $Z$ & axial coordinate in cylindrical coordinates \\
  $\delta_{ij}$ & \textsc{Kronecker} delta \\
  $\theta$ & poloidal angle \\
  $\phi$ & toroidal angle \\
  $\Psi$ & magnetic flux \\
  $\psi$ & flux surface label \\
  \bottomrule
\end{longtable}

\begin{longtable}{l >{\RaggedRight}p{0.8\textwidth}}
  \caption{Symbol decorations} \\
  \toprule
  \textbf{Notation} & \textbf{Description} \\
  \midrule
  \endhead
  \label{tab:decorations}%
  $p_{0}$ & equilibrium $p$ \\
  $\delta p$ & perturbation of $p$ \\
  $p_{n}$ & \textsc{Fourier} coefficient of perturbation of $p$ with toroidal mode number $n$ \\
  $p_{m n}$ & \textsc{Fourier} coefficient of perturbation of $p$ with poloidal mode number $m$ and toroidal mode number $n$ \\
  $p^{(k)}$ & $k$-th summand in series expansion of perturbed $p$ / $k$-th degree of freedom of $p$ in a particular loop \\
  $p^{[k]}$ & $k$-th partial sum in series expansion of perturbed $p$ \\
  \midrule
  $\vec{J}^{\pol}$ & poloidal component of $\vec{J}$ \\
  $\vec{J}^{\tor}$ & toroidal component of $\vec{J}$ \\
  $\vec{J}^{\parallel}$ & component of $\vec{J}$ parallel to $\vec{B}_{0}$ \\
  $\vec{J}^{\perp}$ & component of $\vec{J}$ perpendicular to $\vec{B}_{0}$ \\
  $J^{u}$ & contravariant component of $\vec{J}$ w.r.t.\ coordinate $u$ \\
  $J_{u}$ & covariant component of $\vec{J}$ w.r.t.\ coordinate $u$ \\
  $J_{(u)}$ & physical component of $\vec{J}$ w.r.t.\ coordinate $u$ \\
  $\hat{\vec{n}}$ & unit vector in direction of $\vec{n}$ \\
  \midrule
  $\vec{B} (\vec{r}^{(k)})$ & $\vec{B}$ evaluated at node with index $k$ \\
  $\vec{B} (\Gamma_{e}^{(k)})$ & $\vec{B}$ evaluated at midpoint of edge $e$ of triangle $k$ \\
  $\vec{B} (\Omega^{(k)})$ & $\vec{B}$ evaluated at weighted centroid of triangle $k$ \\
  \bottomrule
\end{longtable}

\section{Arnoldi iterations}
\label{app:Arnoldi}

For an $N \times N$ matrix $\hat{K}$, the \textsc{Arnoldi} algorithm gives the largest $n_{r}$ \textsc{Ritz} eigenvalues $\lambda_{k}$  and the associated eigenvectors $\vec{v}_{k}$ which span the \textsc{Krylov} subspace of $\hat{K}$. To accomplish this, $\hat{K}$ is repeatedly applied to an arbitrary initial vector $\vec{q}_{1}$. In each iteration step, the next \textsc{Arnoldi} vector $\vec{q}_{k}$ is generated and orthonormalized with respect to the previously generated vectors by \textsc{Gram}-\textsc{Schmidt} orthogonalization. Also, entries of an upper \textsc{Hessenberg} matrix $\hat{H}$ are constructed, as outlined in \cref{alg:arnoldi}.
\begin{algorithm}
  \caption{\textsc{Arnoldi} iterations}
  \label{alg:arnoldi}
  \begin{algorithmic}[1]
    \State{$\vec{q}_{1} \gets \frac{\vec{q}_{1}}{\norm{\vec{q}_{1}}}$}
    \For{$k = 2, 3, \dotsc, n_{r}$}
      \State{$\vec{q}_{k} \gets \hat{K} \vec{q}_{k-1}$}
      \For{$j = 1, 2, \dotsc, k-1$}
        \State{$H_{j, k-1} \gets \vec{q}_{j}^{\dagger} \vec{q}_{k}$}
        \State{$\vec{q}_{k} \gets \vec{q}_{k} - H_{j, k-1} \vec{q}_{j}$}
      \EndFor
      \State{$H_{k, k-1} \gets \norm{\vec{q}_{k}}$}
      \State{$\vec{q}_{k} \gets \frac{\vec{q}_{k}}{H_{k, k-1}}$}
    \EndFor
  \end{algorithmic}
\end{algorithm}
Grouping together the $\vec{q}_{k}$ vectors in an $N \times n_{r}$ matrix $\hat{Q}$, an approximation of $\hat{K}$ can be written out as
\begin{gather}
  \hat{K} \approx \hat{Q} \hat{H} \hat{Q}^{\dagger}.
\end{gather}
Diagonalization of $\hat{H}$ via the LAPACK routine \texttt{zhseqr} yields the \textsc{Ritz} eigenvalues $\lambda_{k}$ and application of $\hat{Q}$ on the eigenvectors of $\hat{H}$ obtained via \texttt{zhsein} gives the eigenvectors $\vec{v}_{k}$ associated with $\hat{K}$.

\section{Fourier series of vector quantitites}

$\Bpert$ in symmetry flux coordinates $(\rho, \theta, \phi)$ is given as the \textsc{Fourier} series
\begin{gather}
  \delta B^{k} (\rho, \theta, \phi) = B_{n}^{k}(\rho, \theta) \e^{\im n \phi}.
\end{gather}
$\Bpert$ is also divergence-free and assuming $g = g(\rho, \theta)$, we get
\begin{align}
  0 &= \sqrt{g} \divg \Bpert = \partial_{k} \left( \sqrt{g} \delta B^{k} \right) = \partial_{k} \left( \sqrt{g} B_{n}^{k} \e^{\im n \phi} \right) = \partial_{k} \left( \mathcal{B}_{n}^{k} \e^{\im n \phi} \right) = \\
    &= \partial_{\rho} \left( \mathcal{B}_{n}^{\rho} \right) \e^{\im n \phi} + \mathcal{B}_{n}^{\phi} \partial_{\phi} \left( \e^{\im n \phi} \right) + \partial_{\theta} \left( \mathcal{B}_{n}^{\theta} \right) \e^{\im n \phi} = \\
    &= \underbrace{\e^{\im n \phi}}_{\neq 0} \left( \partial_{\rho} \mathcal{B}_{n}^{\rho} + \im n \mathcal{B}_{n}^{\phi} + \partial_{\theta} \mathcal{B}_{n}^{\theta} \right).
\end{align}

\printbibliography

\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
